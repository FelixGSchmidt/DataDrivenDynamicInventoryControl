{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6dd7a95-3daa-47fe-ac48-433e8922d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import time\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import pyreadr\n",
    "import json\n",
    "import pickle\n",
    "from joblib import dump, load, Parallel, delayed\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efe3de97-88db-4ba5-a7de-674e8ebcc844",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to get predictions\n",
    "def getMeanPred(y_samples,\n",
    "                y_samples_SKU,\n",
    "                ID_samples,\n",
    "                ID_samples_SKU,\n",
    "                weights_ij_global,\n",
    "                weights_ij_local,\n",
    "                params):\n",
    "\n",
    "    # Get T horizon and R horizon rolling\n",
    "    T_horizon = params['T_horizon']\n",
    "    T_horizon_rolling = params['T_horizon_rolling']\n",
    "    \n",
    "    # Initialize\n",
    "    xi_hats_wsaa_global = []\n",
    "    xi_hats_wsaa_local = []\n",
    "    xi_hats_saa = []\n",
    "    xi_acts = []\n",
    "\n",
    "    ## Iterate over full time horizon\n",
    "    for t_current in range(T_horizon):   \n",
    "\n",
    "        # Set current model params\n",
    "        model_params = dict({\n",
    "            'T': min(T_horizon_rolling,T_horizon-t_current),\n",
    "            'N': int(params['sampleUpTo_start']+t_current)\n",
    "        })    \n",
    "        \n",
    "        # Samples of unknown variable (i,t)\n",
    "        xi_hat_global = np.array(\n",
    "            y_samples.iloc[list(ID_samples.sale_yearweek < \n",
    "                           ID_samples_SKU.loc[model_params['N']].sale_yearweek),\n",
    "                                         0:model_params['T']])\n",
    "        \n",
    "        xi_hat_local = np.array(\n",
    "            y_samples_SKU.iloc[0:model_params['N'], 0:model_params['T']])\n",
    "        \n",
    "        xi_act = np.array(y_samples_SKU.iloc[model_params['N'],0:model_params['T']])\n",
    "\n",
    "        # Sample weights (i)\n",
    "        w_hat_global = np.array(weights_ij_global[t_current+1])\n",
    "        w_hat_local = np.array(weights_ij_local[t_current+1])\n",
    "\n",
    "        # Summarize weights and samples - global\n",
    "        xi_hat_global = xi_hat_global[list(w_hat_global > 0)]\n",
    "        w_hat_global = w_hat_global[list(w_hat_global > 0)]\n",
    "\n",
    "        df_global=pd.DataFrame(data=np.hstack(\n",
    "            (w_hat_global.reshape(w_hat_global.shape[0],1), xi_hat_global)), \n",
    "                columns=[-1] + list(range(0,model_params['T']))).groupby(\n",
    "            list(range(0,model_params['T']))).agg(\n",
    "                w_hat_global = (-1, np.sum)).reset_index()\n",
    "\n",
    "        xi_hat_global = np.array(df_global[list(range(0,model_params['T']))])\n",
    "        w_hat_global = np.array([df_global.w_hat_global]).flatten()\n",
    "        \n",
    "        # Summarize weights and samples - global\n",
    "        xi_hat_local = xi_hat_local[list(w_hat_local > 0)]\n",
    "        w_hat_local = w_hat_local[list(w_hat_local > 0)]\n",
    "\n",
    "        df_local=pd.DataFrame(data=np.hstack(\n",
    "            (w_hat_local.reshape(w_hat_local.shape[0],1), xi_hat_local)), \n",
    "                columns=[-1] + list(range(0,model_params['T']))).groupby(\n",
    "            list(range(0,model_params['T']))).agg(\n",
    "                w_hat_local = (-1, np.sum)).reset_index()\n",
    "\n",
    "        xi_hat_local = np.array(df_local[list(range(0,model_params['T']))])\n",
    "        w_hat_local = np.array([df_local.w_hat_local]).flatten()\n",
    "\n",
    "        # Predict Weighted SAA\n",
    "        xi_hats_wsaa_global = xi_hats_wsaa_global + list(sum(xi_hat_global * w_hat_global[:, np.newaxis]))\n",
    "        xi_hats_wsaa_local = xi_hats_wsaa_local + list(sum(xi_hat_local * w_hat_local[:, np.newaxis]))\n",
    "\n",
    "        # Predict SAA\n",
    "        xi_hats_saa = xi_hats_saa + list(sum(np.array(y_samples_SKU.iloc[0:model_params['N'],0:model_params['T']]) * \n",
    "            1/np.array(y_samples_SKU.iloc[0:model_params['N'],0:model_params['T']]).shape[0]))\n",
    "\n",
    "        # Actuals\n",
    "        xi_acts = xi_acts + list(xi_act)\n",
    "\n",
    "    # Average demand predictions\n",
    "    mean_xi_hat_wsaa_global = np.mean(np.array(xi_hats_wsaa_global))\n",
    "    mean_xi_hat_wsaa_local = np.mean(np.array(xi_hats_wsaa_local))\n",
    "    mean_xi_hat_saa = np.mean(np.array(xi_hats_saa))\n",
    "    mean_xi_act = np.mean(np.array(xi_acts))\n",
    "            \n",
    "    # Return\n",
    "    return mean_xi_hat_wsaa_global, mean_xi_hat_wsaa_local, mean_xi_hat_saa, mean_xi_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec5d07c8-659b-48ec-b86c-b4d75308a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to run main script\n",
    "def run(SKU_range, T_horizon_rolling_range):\n",
    "\n",
    "    # Initialize results\n",
    "    MeanPred_results = pd.DataFrame()\n",
    "\n",
    "    # For each SKU\n",
    "    for SKU in SKU_range:\n",
    "\n",
    "        # Status\n",
    "        print('SKU:', SKU)\n",
    "\n",
    "        # For each rolling horizon\n",
    "        for T_horizon_rolling in T_horizon_rolling_range:\n",
    "\n",
    "            # Get weights\n",
    "            with open(PATH_SAMPLES+'/SKU'+str(SKU)+'/Static/Weights'+str(T_horizon_rolling)+'/weights_global_ij.p', 'rb') as f:\n",
    "                weights_ij_global = pickle.load(f)\n",
    "            del f\n",
    "            \n",
    "            with open(PATH_SAMPLES+'/SKU'+str(SKU)+'/Static/Weights'+str(T_horizon_rolling)+'/weights_local_ij.p', 'rb') as f:\n",
    "                weights_ij_local = pickle.load(f)\n",
    "            del f\n",
    "\n",
    "            # Get samples\n",
    "            robj = pyreadr.read_r(PATH_SAMPLES+'/SKU'+str(SKU)+'/Static/TmpFiles'+str(T_horizon_rolling)+'/Y_samples_mv_k.RDS')\n",
    "            y_samples_SKU = robj[None]\n",
    "\n",
    "            robj = pyreadr.read_r(PATH_DATA+'/Y_Data_mv_NEW.RData')\n",
    "            y_samples = robj['Y_Data_mv']\n",
    "\n",
    "            robj = pyreadr.read_r(PATH_SAMPLES+'/SKU'+str(SKU)+'/Static/TmpFiles'+str(T_horizon_rolling)+'/ID_samples_k.RDS')\n",
    "            ID_samples_SKU = robj[None]\n",
    "\n",
    "            robj = pyreadr.read_r(PATH_DATA+'/ID_Data_NEW.RData')\n",
    "            ID_samples = robj['ID_Data']\n",
    "\n",
    "            # Get sampling\n",
    "            robj = pyreadr.read_r(PATH_SAMPLES+'/SKU'+str(SKU)+'/Static/TmpFiles'+str(T_horizon_rolling)+'/sampleUpTo_start.RDS')\n",
    "            sampleUpTo_start = robj[None].iloc[0,0]\n",
    "\n",
    "            # Planning params\n",
    "            params = dict({\n",
    "                'SKU': SKU,\n",
    "                'T_horizon': 13,\n",
    "                'T_horizon_rolling': T_horizon_rolling,\n",
    "                'sampleUpTo_start': sampleUpTo_start\n",
    "            })\n",
    "\n",
    "            # Get predictive performance\n",
    "            result = getMeanPred(y_samples,\n",
    "                                 y_samples_SKU,\n",
    "                                 ID_samples,\n",
    "                                 ID_samples_SKU,\n",
    "                                 weights_ij_global,\n",
    "                                 weights_ij_local,\n",
    "                                 params)\n",
    "            \n",
    "            mean_xi_hat_wsaa_global, mean_xi_hat_wsaa_local, mean_xi_hat_saa, mean_xi_hat = result\n",
    "\n",
    "            # Results\n",
    "            MeanPred_result = pd.DataFrame({\n",
    "                'SKU': [SKU],\n",
    "                'T_horizon_rolling': [T_horizon_rolling],\n",
    "                'meanPred_wsaa_global': [mean_xi_hat_wsaa_global],\n",
    "                'meanPred_wsaa_local': [mean_xi_hat_wsaa_local],\n",
    "                'meanPred_saa': [mean_xi_hat_saa],\n",
    "                'meanAct': [mean_xi_hat]\n",
    "            })\n",
    "\n",
    "\n",
    "            # Store\n",
    "            if not MeanPred_results.empty:\n",
    "                MeanPred_results = MeanPred_results.append(MeanPred_result)   \n",
    "            else:\n",
    "                MeanPred_results = pd.DataFrame(MeanPred_result) \n",
    "\n",
    "        \n",
    "    # Return\n",
    "    return MeanPred_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9bb36c-7d2a-4896-a555-3567482e3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA='/home/fesc/Data'\n",
    "PATH_PARAMS='/home/fesc/Data/Params'\n",
    "PATH_SAMPLES='/home/fesc/Data/Samples'\n",
    "PATH_RESULTS='/home/fesc/Data/Results'\n",
    "PATH_KERNELS='/home/fesc/Data/Kernels'\n",
    "\n",
    "# SKUs\n",
    "SKU_range=range(1,460+1)\n",
    "\n",
    "# Rolling horizons\n",
    "T_horizon_rolling_range=range(1,5+1)\n",
    "\n",
    "# Run\n",
    "MeanPred_results = run(SKU_range, T_horizon_rolling_range)\n",
    "\n",
    "# Save result\n",
    "MeanPred_results.to_csv(path_or_buf=PATH_RESULTS+'/MeanPred.csv' , sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d25fe-9d0f-4b85-8787-3a552aca7205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d343ea-3518-448f-8a14-16244836930a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e0943-155a-468f-ab7a-f62ca04d48da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac097d0-8f96-4375-b8bc-e1a8fdedecbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d0663-ec8e-4a49-bfc9-36f78e53691f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2e3c48-5044-4f83-9115-6d4dd72bd1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6b7358-7dd4-4cda-8709-f6ee9bbfbf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5faea18-456c-4c11-a45a-2a82052b3ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2f86df-298d-4a5a-af3f-09070b36b97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DDDInventoryControl",
   "language": "python",
   "name": "dddinventorycontrol"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

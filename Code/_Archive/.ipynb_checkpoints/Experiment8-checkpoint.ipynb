{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa32c966-eb6a-49ab-8484-fdd0b7e22e0a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b518e25-3378-4cde-9fca-4ea5cccd902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import time\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "from joblib import dump, load, Parallel, delayed\n",
    "import os\n",
    "import itertools\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import Weights Model\n",
    "import WeightsModel3\n",
    "from WeightsModel3 import PreProcessing\n",
    "from WeightsModel3 import RandomForestWeightsModel\n",
    "\n",
    "\n",
    "# Import (Rolling Horizon) Weighted SAA models\n",
    "from WeightedSAA6 import WeightedSAA\n",
    "from WeightedSAA6 import RobustWeightedSAA\n",
    "from WeightedSAA6 import RollingHorizonOptimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d60c56-dbb7-42e2-a8b7-f478cb4dc818",
   "metadata": {},
   "source": [
    "# General paths and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "331e5ab6-1320-4122-be2b-84b7bb7f89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder names as global variables\n",
    "os.chdir('/home/fesc/DataDrivenDynamicInventoryControl/')\n",
    "global PATH_DATA, PATH_WEIGHTSMODEL, PATH_RESULTS\n",
    "\n",
    "PATH_DATA = '/home/fesc/DataDrivenDynamicInventoryControl/Data' \n",
    "PATH_WEIGHTSMODEL = '/home/fesc/DataDrivenDynamicInventoryControl/Data/WeightsModel'\n",
    "PATH_RESULTS = '/home/fesc/DataDrivenDynamicInventoryControl/Data/Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "6948b9d8-5514-4c0c-b4fa-8f5e4bd9e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time period and SKU ranges\n",
    "T = 13                  # Planning horizon T\n",
    "ts = range(1,13+1)      # Periods t=1,...,T of the planning horizon\n",
    "taus = range(0,4+1)     # Look-aheads tau=0,...,4 to use\n",
    "es = [1,3,6,9,12]       # Uncertainty set specifications e=1,...,12\n",
    "SKUs = range(1,460+1)   # Products (SKUs) k=1,...,M\n",
    "\n",
    "# Train/test split (first timePeriods of testing horizon)\n",
    "test_start = 114\n",
    "\n",
    "# Cost param settings\n",
    "cost_params = [\n",
    "\n",
    "    {'CR': 0.50, 'K': 100, 'u': 0.5, 'h': 1, 'b': 1},\n",
    "    {'CR': 0.75, 'K': 100, 'u': 0.5, 'h': 1, 'b': 3},\n",
    "    {'CR': 0.90, 'K': 100, 'u': 0.5, 'h': 1, 'b': 9}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b618b512-5f0f-4c54-811f-c2ee523d5a17",
   "metadata": {},
   "source": [
    "# Training and Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a137c0ad-6243-4390-bd1c-6aff2a2fca74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Global Training and Samping\n",
    "\n",
    "The two global models (using 'Global Training and Sampling') are **Rolling Horizon Global Weighted SAA (GwSAA)**, which is our model, and **Rolling Horizon Global Robust Weighted SAA (GwSAA-R)**, which is the analogous model with robust extension.\n",
    "\n",
    "Given product $k$, period $t$, and look-ahead $\\tau$, both models apply Weighted SAA over the 'global' distribution $\\{\\{w_{j,t,\\tau}^{\\,i}(x_{k,t}^{\\,i}),(d_{j,t}^{\\,i},...,d_{j,t+\\tau}^{\\,i})\\}_{i=1}^{N_{j,t,\\tau}}\\}_{j=1}^{M}$, with weight functions $w_{j,t,\\tau}(\\,\\cdot\\,)$ trained (once for all products) on data $S_{t,\\tau}^{\\,\\text{Global}}=\\{\\{(x_{j,t}^{\\,i},d_{j,t}^{\\,i},...,d_{j,t+\\tau}^{\\,i})\\}_{i=1}^{N_{j,t,\\tau}}\\}_{j=1}^{M}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6c9b9-f722-44f1-8f73-dd8c964a2bbf",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We first load and pre-process the data. This includes reshaping demand time series into $(\\tau+1)$-periods rolling look-ahead horizon sequences.\n",
    "\n",
    "- **ID_Data** (pd.DataFrame) stores identifiers (in particular the product (SKU) identifier and the timePeriod (sale_yearweek) identifier)\n",
    "- **X_Data** (pd.DataFrame) is the 'feature matrix', i.e., each row is a feature vector $x_{j,n}$ where n is the number of training observations (rows) in the data\n",
    "- **Y_Data** (pd.DataFrame) is the demand data $d_{j,n}$ (a times series per product)\n",
    "- **X_Data_Columns** (pd.DataFrame) provides 'selectors' for local vs. global feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "807bbbf8-251d-4807-8915-3d90955a53f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_global_r_z' # reshaped and scaled\n",
    "weightsmodel_name = 'rfwm_global_r_z' # reshaped and scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "3cd9a08d-e0c8-4d6d-b26f-44eef6d7633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "ID_Data = pd.read_csv(PATH_DATA+'/ID_Data.csv')\n",
    "X_Data = pd.read_csv(PATH_DATA+'/X_Data.csv')\n",
    "X_Data_Columns = pd.read_csv(PATH_DATA+'/X_Data_Columns4.csv')\n",
    "Y_Data = pd.read_csv(PATH_DATA+'/Y_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ec22262b-07c2-4fc0-b32f-518b0163ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X_Data_Columns = X_Data_Columns.loc[X_Data_Columns.Global == 'YES']\n",
    "X_Data = X_Data[X_Data_Columns.Feature.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "b67e9b65-8a57-4d7f-a994-a5249ae5563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is sorted by SKU and sale_yearweek for preprocessing\n",
    "data = pd.concat([ID_Data, X_Data, Y_Data], axis=1).sort_values(by=['SKU', 'sale_yearweek']).reset_index(drop=True)\n",
    "ID_Data = data[ID_Data.columns]\n",
    "X_Data = data[X_Data.columns]\n",
    "Y_Data = data[Y_Data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "eeaa0a9f-16fd-49b9-92f2-a788ec46d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature scalers\n",
    "features_to_scale_with = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].ScaleWith.unique()\n",
    "\n",
    "q = 0.975\n",
    "lags = [1,2,3,4,5]\n",
    "\n",
    "x_scalers = {}\n",
    "for t in ts:\n",
    "    x_scalers[t] = {}\n",
    "    for SKU in SKUs:\n",
    "        x_scalers[t][SKU] = {}\n",
    "        for feature_to_scale_with in features_to_scale_with:\n",
    "            z = []\n",
    "            for l in lags:\n",
    "                if feature_to_scale_with+'_lag'+str(l) in X_Data:\n",
    "                    sel = (ID_Data.sale_yearweek <= test_start+t-1) & (ID_Data.SKU == SKU)\n",
    "                    z_ = np.quantile(X_Data.loc[sel][feature_to_scale_with+'_lag'+str(l)], q, method='closest_observation')\n",
    "                    if z_ > 0:\n",
    "                        z += [z_]\n",
    "                    else:\n",
    "                        z += [max(X_Data.loc[sel][feature_to_scale_with+'_lag'+str(l)])]\n",
    "\n",
    "            x_scalers[t][SKU][feature_to_scale_with] = max(z) if max(z) > 0 else 1\n",
    "            \n",
    "_ = joblib.dump(x_scalers, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_x_scalers.joblib')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "a67304fb-079c-4068-b05c-375ec981b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get demand scalers\n",
    "q = 0.975\n",
    "\n",
    "\n",
    "y_scalers = {}\n",
    "for t in ts:\n",
    "    y_scalers[t] = {}\n",
    "    for SKU in SKUs:        \n",
    "        sel = (ID_Data.sale_yearweek <= test_start+t-1) & (ID_Data.SKU == SKU)\n",
    "        z_ = np.quantile(Y_Data.loc[sel]['Y'], q, method='closest_observation')\n",
    "        if z_ > 0:\n",
    "            y_scalers[t][SKU] = z_\n",
    "        else:\n",
    "            y_scalers[t][SKU] = max(Y_Data.loc[sel]['Y']) if max(Y_Data.loc[sel]['Y']) > 0 else 1\n",
    "\n",
    "_ = joblib.dump(y_scalers, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_y_scalers.joblib')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0fc3e-5f10-4ff1-8817-944aced7c2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc22c4f4-2ce2-4e19-8129-885916516c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ae8fd-63a6-474e-b908-e4ddaae26d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "c8007170-24f1-45f8-b06e-74000e544560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class qMaxScaler:\n",
    "    \n",
    "    #### Initialize\n",
    "    def __init__(self, q_outlier=0.999, **kwargs):\n",
    "        \n",
    "        # Quantile up to which data should be considered for fitting the scaler\n",
    "        self.q_outlier = q_outlier\n",
    "        \n",
    "        # Lags to consider for features used for scaling\n",
    "        self.lags = [1,2,3,4,5]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def fit(self, X, features=None, features_to_scale_with=None, **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ...\n",
    "        X: ...\n",
    "        features: ...\n",
    "        features_to_scale_with: ...\n",
    "        kwargs: can provide q_outlier to overwrite default / initialized value of q_outlier\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # Update q_outlier if provided\n",
    "        self.q_outlier = kwargs.get('q_outlier', self.q_outlier)\n",
    "        \n",
    "        # Store features and features_to_scale_with\n",
    "        self.features = features\n",
    "        self.features_to_scale_with = features_to_scale_with\n",
    "\n",
    "        # Initialize\n",
    "        self.scalers = {}\n",
    "\n",
    "        # If both 'features' and 'features_to_scale_with' are provided\n",
    "        if (not features is None) and (not features_to_scale_with is None):\n",
    "            \n",
    "            # For each feature used for scaling, get the scaling value (max of q-quantile per lag of the feature)\n",
    "            for feature_to_scale_with in features_to_scale_with:\n",
    "                z = []\n",
    "                for l in self.lags:\n",
    "                    if feature_to_scale_with+'_lag'+str(l) in features:\n",
    "                        sel = (features == feature_to_scale_with+'_lag'+str(l))\n",
    "                        z_ = np.quantile(X[:,sel], self.q_outlier, method='closest_observation')\n",
    "                        if z_ > 0:\n",
    "                            z += [z_]\n",
    "                        else:\n",
    "                            z += [max(X[:,sel])]\n",
    "\n",
    "                self.scalers[feature_to_scale_with] = max(z) if max(z) > 0 else 1\n",
    "                \n",
    "        # Else, use all columns in X for scaling\n",
    "        else:\n",
    "            \n",
    "            # For each column in X, get the scaling value (max of q-quantile)\n",
    "            for col in range(X.shape[1]):\n",
    "     \n",
    "                z_ = np.quantile(X[:,col], self.q_outlier, method='closest_observation')\n",
    "                if z_ > 0:\n",
    "                    self.scalers[col] = z_\n",
    "                else:\n",
    "                    self.scalers[col] = max(X[:,col]) if max(X[:,col]) > 0 else 1\n",
    "\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    \n",
    "    def transform(self, **kwargs):\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "c117d35f-b91c-4a81-8c9d-d0aa62c35364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit feature scaler\n",
    "x_scalers = {}\n",
    "for t in ts:\n",
    "    x_scalers[t] = {}\n",
    "    for SKU in SKUs:\n",
    "        scaler = qMaxScaler(q_outlier=0.975)\n",
    "        X = np.array(X_Data.loc[(ID_Data.sale_yearweek <= test_start+t-1) & (ID_Data.SKU == SKU)])           \n",
    "        features = X_Data.columns\n",
    "        features_to_scale_with = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].ScaleWith.unique()\n",
    "        x_scalers[t][SKU] = scaler.fit(X, features, features_to_scale_with)\n",
    "        \n",
    "_ = joblib.dump(x_scalers, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_x_scalers.joblib')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "4144128d-a83f-4474-985f-cb438939d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit demand scaler\n",
    "y_scalers = {}\n",
    "for t in ts:\n",
    "    y_scalers[t] = {}\n",
    "    for SKU in SKUs:\n",
    "        scaler = qMaxScaler(q_outlier=0.975)\n",
    "        y = np.array(Y_Data.loc[(ID_Data.sale_yearweek <= test_start+t-1) & (ID_Data.SKU == SKU)])           \n",
    "        y_scalers[t][SKU] = scaler.fit(y)\n",
    "        \n",
    "_ = joblib.dump(y_scalers, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_y_scalers.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "271d6a3f-3130-4ef8-ac4f-cf10b2c13b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159a9e7-c3dc-4e92-8696-a2b1aa199319",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37341b41-93ee-4468-8f2b-82347e973fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c14675-ee83-44da-b853-60a2e95d16d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdfce92-30af-4cfb-9ace-38d27363b795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b055ad-a018-4bd9-84d4-262ed906bdf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c642ce-6388-4148-988e-8d0c85b128fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5abd9-7207-47e9-b917-86d160749d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc98de07-b586-4346-871b-adac434d47d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315780f8-b058-461f-84c8-5e3e40067d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f92e1d-2c9c-485d-b260-b9d1686df4e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29b652-8044-49ba-ab95-fcb5d53f5270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489d718-d0a2-4f09-a5a3-7506cfb7474a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bd1195dc-d49c-40e0-a49b-89e9f0102d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83997644-eb7f-41a2-858b-34fc05154084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf49538-436f-4cbc-a666-6737c28a5349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9345c8c-6d6d-4f60-8ecb-7beddd417675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "bc60c5cb-87f7-42bb-b4a7-759ed7fdc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "acfd4b8e-3299-4e11-b90a-4a54d0734613",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Data_z = copy.deepcopy(X_Data)\n",
    "vars_to_scale = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].Feature\n",
    "vars_to_scale_with = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].ScaleWith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "8d08e314-ae4b-4626-bd77-9b6733fe98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for SKU in SKUs:\n",
    "    for var_to_scale, var_to_scale_with in zip(vars_to_scale, vars_to_scale_with):\n",
    "\n",
    "        X_Data_z.loc[ID_Data.SKU == SKU, var_to_scale] = (\n",
    "            X_Data.loc[ID_Data.SKU == SKU][var_to_scale] / x_scalers[t][SKU].scalers[var_to_scale_with]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb164f6-7b18-40e0-a24b-2983e6961bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d8f803-e8c9-4ce6-b635-78f477f2a811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe00b34-6fcc-449f-ad82-90909d462304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09289b7c-c0ca-45da-b433-2a665f75d090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f05e0-7437-4220-a0ee-902539dbf414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1ffcf-5d36-41b2-8ae1-a2bb4a21eefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2fffa0-5bf5-4732-bb69-bed4b1217518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f313055-05b5-45ab-8654-ef309f577289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "5793eb30-846e-4624-a899-0af63d2ad46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-period demand vectors\n",
    "data = pd.concat([ID_Data, Y_Data], axis=1)\n",
    "Y = {}\n",
    "for tau in taus:\n",
    "    Y['Y'+str(tau)] = data.groupby(['SKU']).shift(-tau)['Y']\n",
    "Y_Data = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd893890-6849-48fe-8568-5887a176f1c8",
   "metadata": {},
   "source": [
    "### Weights model\n",
    "\n",
    "The weights models - and thus the data used, weight functions, and weights per sample - are the same for the two global models **GwSAA** and **GwSAA-R**. First, we tune the hyper parameters of the random forest weights model for each given look-ahead $\\tau$ (as for each look-ahead $\\tau$ we have a different response for the multi-output random forest regressor). Second, we fit all weight functions (for each look-ahead $\\tau=0,...,4$ and over periods $t=1,...,T$) and generate all weights (for each look-ahead $\\tau=0,...,4$, over periods $t=1,...,T$, and for each product (SKU) $k=1,...,M$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bcee6-737b-4ac0-b412-837607c2edfb",
   "metadata": {},
   "source": [
    "#### Tune weights model\n",
    "\n",
    "To tune the hyper parameters of the global random forest weights model, we use 3-fold rolling timeseries cross-validation on the training data and perform random search with 100 iterations over the specified hyper parameter search grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b187aa7-4edd-4288-88ea-fe5a6ca96a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_params = {\n",
    "    'oob_score': True,\n",
    "    'random_state': 12345,\n",
    "    'n_jobs': 4,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "hyper_params_grid = {\n",
    "    'n_estimators': [1000],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [x for x in range(20, 1000, 20)],  \n",
    "    'min_samples_leaf': [x for x in range(10, 1000, 10)],  \n",
    "    'max_features': [x for x in range(8, 256, 8)],   \n",
    "    'max_leaf_nodes': [None],\n",
    "    'min_impurity_decrease': [0.0],\n",
    "    'bootstrap': [True],\n",
    "    'max_samples': [0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "}    \n",
    "\n",
    "\n",
    "tuning_params = {     \n",
    "    'n_iter': 100,\n",
    "    'scoring': {'MSE': 'neg_mean_squared_error'},\n",
    "    'return_train_score': True,\n",
    "    'refit': 'MSE',\n",
    "    'random_state': 12345,\n",
    "    'n_jobs': 8,\n",
    "    'verbose': 2\n",
    "}    \n",
    "\n",
    "random_search = True\n",
    "print_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "2a6b5767-08c3-445c-901c-9774e1204273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess features\n",
    "X_Data_z = copy.deepcopy(X_Data)\n",
    "features_to_scale = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].Feature\n",
    "features_to_scale_with = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].ScaleWith\n",
    "\n",
    "t=1\n",
    "for SKU in SKUs:\n",
    "    for feature_to_scale, feature_to_scale_with in zip(features_to_scale, features_to_scale_with):\n",
    "\n",
    "        X_Data_z.loc[ID_Data.SKU == SKU, feature_to_scale] = (\n",
    "            X_Data.loc[ID_Data.SKU == SKU][feature_to_scale] / x_scalers[t][SKU].scalers[feature_to_scale_with]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "a10664a2-3006-4deb-8122-be4e44ff47f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess demands\n",
    "Y_Data_z = copy.deepcopy(Y_Data)\n",
    "\n",
    "t=1\n",
    "for SKU in SKUs:\n",
    "    Y_Data_z.loc[ID_Data.SKU == SKU, 'Y'] = (\n",
    "        Y_Data.loc[ID_Data.SKU == SKU]['Y'] / y_scalers[t][SKU].scalers[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a52388fa-4a08-406b-bbd6-3cf4c7d7e00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-period demand vectors\n",
    "data = pd.concat([ID_Data, Y_Data], axis=1)\n",
    "Y = {}\n",
    "for tau in taus:\n",
    "    Y['Y'+str(tau)] = data.groupby(['SKU']).shift(-tau)['Y']\n",
    "Y_Data = pd.DataFrame(Y)\n",
    "\n",
    "data = pd.concat([ID_Data, Y_Data_z], axis=1)\n",
    "Y_z = {}\n",
    "for tau in taus:\n",
    "    Y_z['Y'+str(tau)] = data.groupby(['SKU']).shift(-tau)['Y']\n",
    "Y_Data_z = pd.DataFrame(Y_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "acafca6c-4b90-42a6-b2c2-ba26c176707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_params = {\n",
    "    'n_jobs': 64,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "b46e596c-b9a5-4b6b-9d8a-727bb8e4f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {}\n",
    "\n",
    "\n",
    "hyper_params[0] = {\n",
    "    \n",
    "    'max_features': 144, \n",
    "    'min_samples_leaf': 10,\n",
    "    'n_estimators': 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "3a3ec9da-2e1e-4ef4-81f7-feb4f3d18af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Look-ahead tau=0 (tau'=0), period t=1...\n"
     ]
    }
   ],
   "source": [
    "tau=0\n",
    "    \n",
    "# Initialize\n",
    "samples, weightfunctions, weightfunctions_times, weights, weights_times = {}, {}, {}, {}, {}\n",
    "\n",
    "t=1\n",
    "\n",
    "# Adjust look-ahead tau to account for end of horizon\n",
    "tau_ = min(tau,T-t)\n",
    "\n",
    "# Status\n",
    "print('#### Look-ahead tau='+str(tau)+' (tau\\'='+str(tau_)+'), period t='+str(t)+'...')\n",
    "start_time = dt.datetime.now().replace(microsecond=0)\n",
    "\n",
    "# Generate samples, fit weight functions, and generate weights (based on tuned weights model)\n",
    "weightsmodel = RandomForestWeightsModel(hyper_params=hyper_params[tau_])\n",
    "\n",
    "res = weightsmodel.training_and_sampling(ID_Data, X_Data_z, Y_Data_z, tau=tau_, timePeriods=ID_Data.sale_yearweek,\n",
    "                                         timePeriodsTestStart=test_start+t-1, model_params=model_params)\n",
    "samples[t], weightfunctions[t], weightfunctions_times[t], weights[t], weights_times[t] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324d538e-0b84-4eb4-854c-4a5b56e5f7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d2304-73b5-43ae-9c33-f5b56c4ab7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "97513c47-5037-4e18-bd53-b23fca5a59b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_z = weightsmodel.weightsmodel.predict(samples[1]['X_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "21acf871-1c3b-4870-834d-0348288ac8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47312, 4)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[1]['id_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "489d76f7-bbc3-4b57-bcc2-15ab784b3368",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_zz = {}\n",
    "for SKU in SKUs:\n",
    "    y_pred_zz[SKU] = y_pred_z[samples[1]['id_train'].SKU == SKU] * y_scalers[1][SKU].scalers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d4afae-1f8f-40ad-8e14-cb2e743ab8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c581e16-b2c1-494f-92df-b8297a48e9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "18c33ca3-ae77-48c2-820c-b789c17fd9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_not_scaled = joblib.load(PATH_WEIGHTSMODEL+'/rfwm_global_not_reshaped_old_rf_params_samples_tau0.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "88dc3684-3d2e-4037-beab-ed96bfa845d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightfunctions_not_scaled = joblib.load(PATH_WEIGHTSMODEL+'/rfwm_global_not_reshaped_old_rf_params_weightfunctions_tau0.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "2e106c60-2cc6-4726-b787-e00019848ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = weightfunctions_not_scaled[1].weightsmodel.predict(samples_not_scaled[1]['X_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "60d86351-0ec1-4ef6-b558-43964bea3db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47312,)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "76bb496b-e906-4be0-abf9-789e07cb02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = samples_not_scaled[1]['y_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "8fcc6dcc-c903-402a-aaf3-defcecc89fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47312,)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "0e8570f3-4749-42d6-83e7-73d3b2042205",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_z = []\n",
    "mse = []\n",
    "for SKU in SKUs:\n",
    "    mse_z += [np.mean((y_pred_zz[SKU]-y[samples_not_scaled[1]['id_train'].SKU==SKU])**2)]\n",
    "    mse += [np.mean((y_pred[samples_not_scaled[1]['id_train'].SKU==SKU]-y[samples_not_scaled[1]['id_train'].SKU==SKU])**2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "3570bc34-d99d-49f2-bf51-0b108bc9707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'SKU': SKUs, 'mse_z': mse_z, 'mse': mse})\n",
    "test['diff'] = test.mse_z / test.mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "fa0a6a6c-404c-4a9d-88b9-f5198a648d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>mse_z</th>\n",
       "      <th>mse</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>4.600000e+02</td>\n",
       "      <td>4.600000e+02</td>\n",
       "      <td>460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>230.500000</td>\n",
       "      <td>1.490397e+06</td>\n",
       "      <td>1.559714e+06</td>\n",
       "      <td>0.925545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132.934821</td>\n",
       "      <td>1.821121e+07</td>\n",
       "      <td>1.860356e+07</td>\n",
       "      <td>0.126160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.744011e-03</td>\n",
       "      <td>1.119469e-02</td>\n",
       "      <td>0.155789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>115.750000</td>\n",
       "      <td>1.518587e+01</td>\n",
       "      <td>1.616273e+01</td>\n",
       "      <td>0.869915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>230.500000</td>\n",
       "      <td>2.162103e+02</td>\n",
       "      <td>2.385135e+02</td>\n",
       "      <td>0.938197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>345.250000</td>\n",
       "      <td>4.062745e+03</td>\n",
       "      <td>4.355276e+03</td>\n",
       "      <td>0.986222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>3.282258e+08</td>\n",
       "      <td>3.316428e+08</td>\n",
       "      <td>1.513610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SKU         mse_z           mse        diff\n",
       "count  460.000000  4.600000e+02  4.600000e+02  460.000000\n",
       "mean   230.500000  1.490397e+06  1.559714e+06    0.925545\n",
       "std    132.934821  1.821121e+07  1.860356e+07    0.126160\n",
       "min      1.000000  1.744011e-03  1.119469e-02    0.155789\n",
       "25%    115.750000  1.518587e+01  1.616273e+01    0.869915\n",
       "50%    230.500000  2.162103e+02  2.385135e+02    0.938197\n",
       "75%    345.250000  4.062745e+03  4.355276e+03    0.986222\n",
       "max    460.000000  3.282258e+08  3.316428e+08    1.513610"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "dff3f2b9-b3ee-4f2f-9285-d885ece19fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>mse_z</th>\n",
       "      <th>mse</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>4.600000e+02</td>\n",
       "      <td>4.600000e+02</td>\n",
       "      <td>460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>230.500000</td>\n",
       "      <td>1.490397e+06</td>\n",
       "      <td>1.559714e+06</td>\n",
       "      <td>0.925545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>132.934821</td>\n",
       "      <td>1.821121e+07</td>\n",
       "      <td>1.860356e+07</td>\n",
       "      <td>0.126160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.744011e-03</td>\n",
       "      <td>1.119469e-02</td>\n",
       "      <td>0.155789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>115.750000</td>\n",
       "      <td>1.518587e+01</td>\n",
       "      <td>1.616273e+01</td>\n",
       "      <td>0.869915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>230.500000</td>\n",
       "      <td>2.162103e+02</td>\n",
       "      <td>2.385135e+02</td>\n",
       "      <td>0.938197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>345.250000</td>\n",
       "      <td>4.062745e+03</td>\n",
       "      <td>4.355276e+03</td>\n",
       "      <td>0.986222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>460.000000</td>\n",
       "      <td>3.282258e+08</td>\n",
       "      <td>3.316428e+08</td>\n",
       "      <td>1.513610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SKU         mse_z           mse        diff\n",
       "count  460.000000  4.600000e+02  4.600000e+02  460.000000\n",
       "mean   230.500000  1.490397e+06  1.559714e+06    0.925545\n",
       "std    132.934821  1.821121e+07  1.860356e+07    0.126160\n",
       "min      1.000000  1.744011e-03  1.119469e-02    0.155789\n",
       "25%    115.750000  1.518587e+01  1.616273e+01    0.869915\n",
       "50%    230.500000  2.162103e+02  2.385135e+02    0.938197\n",
       "75%    345.250000  4.062745e+03  4.355276e+03    0.986222\n",
       "max    460.000000  3.282258e+08  3.316428e+08    1.513610"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977ab2f-4db8-43ea-a72b-7cfa82afd102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58d775-8ac9-438e-a8d2-c4dcb748db0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708da6c-16e8-4d6f-9fbc-a38a1cfbbda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "abfca5fe-a0a9-46c5-9338-7e11cf852da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   3,   4,   4,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  79,\n",
       "         0,  76,   0,  83,   0,  78,   0,   9,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,  79,   0,  76,   0,  82,   0,  77,   0,   8,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,  80,   0,  77,   0,\n",
       "        82,   0,  77,   0,   7,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,  82,   0,  79,   0,  83,   0,  77,   0,   7,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,  84,   0,  81,   0,  85,   0,  78,\n",
       "         0,   8,   0,   0,   0,   0,   0,   0,   0,   0,   0, 103,   0,\n",
       "        96,   0, 111,   0,  98,   0,  23,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.isinf(np.array(X_Data_z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "15d32af9-856d-4605-ae3e-903b8cea5bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pharmacies_lag1</th>\n",
       "      <th>n_SKU_lag1</th>\n",
       "      <th>n_SKU_x_brand_lag1</th>\n",
       "      <th>n_SKU_x_brand_x_strength_lag1</th>\n",
       "      <th>SKU_n_variants_lag1</th>\n",
       "      <th>SKU_n_pharmacies_lag1</th>\n",
       "      <th>SKU_avg_variants_lag1</th>\n",
       "      <th>SKU_dqs_min_lag1</th>\n",
       "      <th>SKU_dqs_median_lag1</th>\n",
       "      <th>SKU_dqs_mean_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>nwt_movav_cluster1</th>\n",
       "      <th>nwt_movav_cluster2</th>\n",
       "      <th>nwt_movav_cluster3</th>\n",
       "      <th>nwt_movav_cluster4</th>\n",
       "      <th>nwt_movav_cluster5</th>\n",
       "      <th>nwt_movav_cluster6</th>\n",
       "      <th>nwt_movav_cluster7</th>\n",
       "      <th>nwt_movav_cluster8</th>\n",
       "      <th>nwt_movav_cluster9</th>\n",
       "      <th>nwt_movav_cluster10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>297</td>\n",
       "      <td>1638</td>\n",
       "      <td>2060</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025112</td>\n",
       "      <td>...</td>\n",
       "      <td>68.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>93.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>308</td>\n",
       "      <td>1741</td>\n",
       "      <td>2206</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.763889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.023996</td>\n",
       "      <td>...</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>316</td>\n",
       "      <td>1867</td>\n",
       "      <td>2373</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>89.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>324</td>\n",
       "      <td>2006</td>\n",
       "      <td>2557</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.109890</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>337</td>\n",
       "      <td>2129</td>\n",
       "      <td>2722</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.817308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>...</td>\n",
       "      <td>71.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>109.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53287</th>\n",
       "      <td>176</td>\n",
       "      <td>449</td>\n",
       "      <td>11205</td>\n",
       "      <td>15210</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039683</td>\n",
       "      <td>...</td>\n",
       "      <td>847.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1270.2</td>\n",
       "      <td>23.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53288</th>\n",
       "      <td>179</td>\n",
       "      <td>449</td>\n",
       "      <td>10919</td>\n",
       "      <td>14827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>...</td>\n",
       "      <td>846.6</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1265.8</td>\n",
       "      <td>26.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1301.2</td>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53289</th>\n",
       "      <td>182</td>\n",
       "      <td>450</td>\n",
       "      <td>10753</td>\n",
       "      <td>14613</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.158730</td>\n",
       "      <td>...</td>\n",
       "      <td>845.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1283.2</td>\n",
       "      <td>27.4</td>\n",
       "      <td>27.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53290</th>\n",
       "      <td>180</td>\n",
       "      <td>452</td>\n",
       "      <td>10495</td>\n",
       "      <td>14209</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>836.6</td>\n",
       "      <td>29.2</td>\n",
       "      <td>1277.4</td>\n",
       "      <td>26.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1373.4</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53291</th>\n",
       "      <td>187</td>\n",
       "      <td>453</td>\n",
       "      <td>10277</td>\n",
       "      <td>13833</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>...</td>\n",
       "      <td>826.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>1268.8</td>\n",
       "      <td>26.4</td>\n",
       "      <td>27.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1418.6</td>\n",
       "      <td>41.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53292 rows  410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_pharmacies_lag1  n_SKU_lag1  n_SKU_x_brand_lag1  \\\n",
       "0                     13         297                1638   \n",
       "1                     15         308                1741   \n",
       "2                     20         316                1867   \n",
       "3                     19         324                2006   \n",
       "4                     22         337                2129   \n",
       "...                  ...         ...                 ...   \n",
       "53287                176         449               11205   \n",
       "53288                179         449               10919   \n",
       "53289                182         450               10753   \n",
       "53290                180         452               10495   \n",
       "53291                187         453               10277   \n",
       "\n",
       "       n_SKU_x_brand_x_strength_lag1  SKU_n_variants_lag1  \\\n",
       "0                               2060             0.151515   \n",
       "1                               2206             0.121212   \n",
       "2                               2373             0.121212   \n",
       "3                               2557             0.090909   \n",
       "4                               2722             0.151515   \n",
       "...                              ...                  ...   \n",
       "53287                          15210             0.666667   \n",
       "53288                          14827             1.000000   \n",
       "53289                          14613             1.000000   \n",
       "53290                          14209             0.000000   \n",
       "53291                          13833             0.333333   \n",
       "\n",
       "       SKU_n_pharmacies_lag1  SKU_avg_variants_lag1  SKU_dqs_min_lag1  \\\n",
       "0                   0.098901               0.694444               0.0   \n",
       "1                   0.098901               0.763889               0.0   \n",
       "2                   0.098901               0.833333               0.0   \n",
       "3                   0.109890               0.812500               0.0   \n",
       "4                   0.142857               0.817308               0.0   \n",
       "...                      ...                    ...               ...   \n",
       "53287               1.000000               1.000000               0.0   \n",
       "53288               0.800000               1.000000               0.0   \n",
       "53289               1.000000               1.000000               0.0   \n",
       "53290               0.400000               1.000000               0.0   \n",
       "53291               0.400000               1.000000               0.0   \n",
       "\n",
       "       SKU_dqs_median_lag1  SKU_dqs_mean_lag1  ...  nwt_movav_cluster1  \\\n",
       "0                 0.000000           0.025112  ...                68.2   \n",
       "1                 0.015625           0.023996  ...                61.0   \n",
       "2                 0.000000           0.013393  ...                63.0   \n",
       "3                 0.015625           0.013393  ...                68.0   \n",
       "4                 0.046875           0.066406  ...                71.4   \n",
       "...                    ...                ...  ...                 ...   \n",
       "53287             0.000000           0.039683  ...               847.0   \n",
       "53288             0.000000           0.126984  ...               846.6   \n",
       "53289             0.055556           0.158730  ...               845.0   \n",
       "53290             0.000000           0.000000  ...               836.6   \n",
       "53291             0.000000           0.238095  ...               826.4   \n",
       "\n",
       "       nwt_movav_cluster2  nwt_movav_cluster3  nwt_movav_cluster4  \\\n",
       "0                     2.0                93.4                 0.6   \n",
       "1                     2.6                89.6                 0.2   \n",
       "2                     3.8                89.6                 0.2   \n",
       "3                     4.0               100.8                 0.6   \n",
       "4                     4.2               109.4                 0.6   \n",
       "...                   ...                 ...                 ...   \n",
       "53287                24.2              1270.2                23.4   \n",
       "53288                27.4              1265.8                26.4   \n",
       "53289                26.0              1283.2                27.4   \n",
       "53290                29.2              1277.4                26.6   \n",
       "53291                29.8              1268.8                26.4   \n",
       "\n",
       "       nwt_movav_cluster5  nwt_movav_cluster6  nwt_movav_cluster7  \\\n",
       "0                     1.2                 0.6                 0.4   \n",
       "1                     0.6                 0.4                 0.2   \n",
       "2                     1.8                 0.4                 0.0   \n",
       "3                     1.4                 0.0                 0.2   \n",
       "4                     1.8                 0.2                 0.2   \n",
       "...                   ...                 ...                 ...   \n",
       "53287                34.0                 2.4                 0.6   \n",
       "53288                29.8                 3.2                 0.4   \n",
       "53289                27.8                 3.0                 0.8   \n",
       "53290                28.0                 4.0                 1.4   \n",
       "53291                27.4                 3.2                 1.6   \n",
       "\n",
       "       nwt_movav_cluster8  nwt_movav_cluster9  nwt_movav_cluster10  \n",
       "0                     0.4               188.0                  0.2  \n",
       "1                     0.0               181.0                  0.0  \n",
       "2                     0.0               180.2                  0.0  \n",
       "3                     0.0               188.0                  0.0  \n",
       "4                     0.0               198.8                  0.2  \n",
       "...                   ...                 ...                  ...  \n",
       "53287                 0.0              1302.0                 39.4  \n",
       "53288                 0.0              1301.2                 38.6  \n",
       "53289                 0.0              1331.0                 39.0  \n",
       "53290                 0.0              1373.4                 40.0  \n",
       "53291                 0.0              1418.6                 41.8  \n",
       "\n",
       "[53292 rows x 410 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Data_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "bab7777b-6861-497e-b934-2a02cc95f13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>sale_year</th>\n",
       "      <th>sale_week</th>\n",
       "      <th>sale_yearweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13558</th>\n",
       "      <td>117</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>13</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13565</th>\n",
       "      <td>117</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>20</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13566</th>\n",
       "      <td>117</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>21</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SKU  sale_year  sale_week  sale_yearweek\n",
       "13558  117     2019.0         13          117.0\n",
       "13565  117     2019.0         20          124.0\n",
       "13566  117     2019.0         21          125.0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_Data.loc[(X_Data_z.SKU_n_variants_lag1 == np.inf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "04f1cb35-0622-41cf-916b-b96db8e7543a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SKU_n_variants': 0,\n",
       " 'SKU_n_pharmacies': 0,\n",
       " 'SKU_avg_variants': 0.0,\n",
       " 'SKU_dqs_max': 1,\n",
       " 'SKU_wqs': 1,\n",
       " 'SKU_tbt_max': 707.1138657,\n",
       " 'SKU_ndt_max': 1,\n",
       " 'SKU_nwt': 1,\n",
       " 'SKU_unit_discount_max': 0.0,\n",
       " 'SKU_unit_price_max': 900.0}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_scalers[1][117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "a3f795c2-04e8-4f3d-8870-29c9a03cf81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_pharmacies_lag1</th>\n",
       "      <th>n_SKU_lag1</th>\n",
       "      <th>n_SKU_x_brand_lag1</th>\n",
       "      <th>n_SKU_x_brand_x_strength_lag1</th>\n",
       "      <th>SKU_n_variants_lag1</th>\n",
       "      <th>SKU_n_pharmacies_lag1</th>\n",
       "      <th>SKU_avg_variants_lag1</th>\n",
       "      <th>SKU_dqs_min_lag1</th>\n",
       "      <th>SKU_dqs_median_lag1</th>\n",
       "      <th>SKU_dqs_mean_lag1</th>\n",
       "      <th>...</th>\n",
       "      <th>nwt_movav_cluster1</th>\n",
       "      <th>nwt_movav_cluster2</th>\n",
       "      <th>nwt_movav_cluster3</th>\n",
       "      <th>nwt_movav_cluster4</th>\n",
       "      <th>nwt_movav_cluster5</th>\n",
       "      <th>nwt_movav_cluster6</th>\n",
       "      <th>nwt_movav_cluster7</th>\n",
       "      <th>nwt_movav_cluster8</th>\n",
       "      <th>nwt_movav_cluster9</th>\n",
       "      <th>nwt_movav_cluster10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13461</th>\n",
       "      <td>37</td>\n",
       "      <td>386</td>\n",
       "      <td>3373</td>\n",
       "      <td>4298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>101.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>318.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13462</th>\n",
       "      <td>40</td>\n",
       "      <td>394</td>\n",
       "      <td>3540</td>\n",
       "      <td>4514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>205.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>344.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13463</th>\n",
       "      <td>40</td>\n",
       "      <td>399</td>\n",
       "      <td>3745</td>\n",
       "      <td>4778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>110.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>233.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13464</th>\n",
       "      <td>40</td>\n",
       "      <td>407</td>\n",
       "      <td>3867</td>\n",
       "      <td>4936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>122.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>254.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>420.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13465</th>\n",
       "      <td>41</td>\n",
       "      <td>414</td>\n",
       "      <td>4007</td>\n",
       "      <td>5102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>131.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>284.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>449.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13563</th>\n",
       "      <td>176</td>\n",
       "      <td>449</td>\n",
       "      <td>11205</td>\n",
       "      <td>15210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>847.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>1270.2</td>\n",
       "      <td>23.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1302.0</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13564</th>\n",
       "      <td>179</td>\n",
       "      <td>449</td>\n",
       "      <td>10919</td>\n",
       "      <td>14827</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>846.6</td>\n",
       "      <td>27.4</td>\n",
       "      <td>1265.8</td>\n",
       "      <td>26.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1301.2</td>\n",
       "      <td>38.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13565</th>\n",
       "      <td>182</td>\n",
       "      <td>450</td>\n",
       "      <td>10753</td>\n",
       "      <td>14613</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>845.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1283.2</td>\n",
       "      <td>27.4</td>\n",
       "      <td>27.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1331.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13566</th>\n",
       "      <td>180</td>\n",
       "      <td>452</td>\n",
       "      <td>10495</td>\n",
       "      <td>14209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>836.6</td>\n",
       "      <td>29.2</td>\n",
       "      <td>1277.4</td>\n",
       "      <td>26.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1373.4</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13567</th>\n",
       "      <td>187</td>\n",
       "      <td>453</td>\n",
       "      <td>10277</td>\n",
       "      <td>13833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>826.4</td>\n",
       "      <td>29.8</td>\n",
       "      <td>1268.8</td>\n",
       "      <td>26.4</td>\n",
       "      <td>27.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1418.6</td>\n",
       "      <td>41.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows  410 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n_pharmacies_lag1  n_SKU_lag1  n_SKU_x_brand_lag1  \\\n",
       "13461                 37         386                3373   \n",
       "13462                 40         394                3540   \n",
       "13463                 40         399                3745   \n",
       "13464                 40         407                3867   \n",
       "13465                 41         414                4007   \n",
       "...                  ...         ...                 ...   \n",
       "13563                176         449               11205   \n",
       "13564                179         449               10919   \n",
       "13565                182         450               10753   \n",
       "13566                180         452               10495   \n",
       "13567                187         453               10277   \n",
       "\n",
       "       n_SKU_x_brand_x_strength_lag1  SKU_n_variants_lag1  \\\n",
       "13461                           4298                    0   \n",
       "13462                           4514                    0   \n",
       "13463                           4778                    0   \n",
       "13464                           4936                    0   \n",
       "13465                           5102                    0   \n",
       "...                              ...                  ...   \n",
       "13563                          15210                    0   \n",
       "13564                          14827                    0   \n",
       "13565                          14613                    1   \n",
       "13566                          14209                    1   \n",
       "13567                          13833                    0   \n",
       "\n",
       "       SKU_n_pharmacies_lag1  SKU_avg_variants_lag1  SKU_dqs_min_lag1  \\\n",
       "13461                      0                    0.0                 0   \n",
       "13462                      0                    0.0                 0   \n",
       "13463                      0                    0.0                 0   \n",
       "13464                      0                    0.0                 0   \n",
       "13465                      0                    0.0                 0   \n",
       "...                      ...                    ...               ...   \n",
       "13563                      0                    0.0                 0   \n",
       "13564                      0                    0.0                 0   \n",
       "13565                      1                    1.0                 0   \n",
       "13566                      1                    1.0                 0   \n",
       "13567                      1                    1.0                 0   \n",
       "\n",
       "       SKU_dqs_median_lag1  SKU_dqs_mean_lag1  ...  nwt_movav_cluster1  \\\n",
       "13461                  0.0           0.000000  ...               101.2   \n",
       "13462                  0.0           0.000000  ...               104.0   \n",
       "13463                  0.0           0.000000  ...               110.8   \n",
       "13464                  0.0           0.000000  ...               122.4   \n",
       "13465                  0.0           0.000000  ...               131.2   \n",
       "...                    ...                ...  ...                 ...   \n",
       "13563                  0.0           0.000000  ...               847.0   \n",
       "13564                  0.0           0.000000  ...               846.6   \n",
       "13565                  0.0           0.142857  ...               845.0   \n",
       "13566                  0.0           0.142857  ...               836.6   \n",
       "13567                  0.0           0.000000  ...               826.4   \n",
       "\n",
       "       nwt_movav_cluster2  nwt_movav_cluster3  nwt_movav_cluster4  \\\n",
       "13461                 3.6               183.0                 1.4   \n",
       "13462                 3.4               205.2                 1.6   \n",
       "13463                 5.0               233.4                 2.2   \n",
       "13464                 5.8               254.8                 2.6   \n",
       "13465                 6.2               284.2                 2.2   \n",
       "...                   ...                 ...                 ...   \n",
       "13563                24.2              1270.2                23.4   \n",
       "13564                27.4              1265.8                26.4   \n",
       "13565                26.0              1283.2                27.4   \n",
       "13566                29.2              1277.4                26.6   \n",
       "13567                29.8              1268.8                26.4   \n",
       "\n",
       "       nwt_movav_cluster5  nwt_movav_cluster6  nwt_movav_cluster7  \\\n",
       "13461                 3.6                 0.4                 0.2   \n",
       "13462                 4.2                 0.4                 0.2   \n",
       "13463                 4.2                 0.4                 0.4   \n",
       "13464                 4.4                 0.6                 0.4   \n",
       "13465                 4.6                 0.6                 0.8   \n",
       "...                   ...                 ...                 ...   \n",
       "13563                34.0                 2.4                 0.6   \n",
       "13564                29.8                 3.2                 0.4   \n",
       "13565                27.8                 3.0                 0.8   \n",
       "13566                28.0                 4.0                 1.4   \n",
       "13567                27.4                 3.2                 1.6   \n",
       "\n",
       "       nwt_movav_cluster8  nwt_movav_cluster9  nwt_movav_cluster10  \n",
       "13461                 0.0               318.0                  0.8  \n",
       "13462                 0.0               344.6                  0.4  \n",
       "13463                 0.0               377.0                  0.4  \n",
       "13464                 0.0               420.2                  0.6  \n",
       "13465                 0.4               449.2                  1.0  \n",
       "...                   ...                 ...                  ...  \n",
       "13563                 0.0              1302.0                 39.4  \n",
       "13564                 0.0              1301.2                 38.6  \n",
       "13565                 0.0              1331.0                 39.0  \n",
       "13566                 0.0              1373.4                 40.0  \n",
       "13567                 0.0              1418.6                 41.8  \n",
       "\n",
       "[107 rows x 410 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Data.loc[ID_Data.SKU==117]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5a9135b7-ee65-4491-ab8c-d90da739e85a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y0</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>Y3</th>\n",
       "      <th>Y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>103.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.028302</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.029126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.165856</td>\n",
       "      <td>0.166622</td>\n",
       "      <td>0.167398</td>\n",
       "      <td>0.168185</td>\n",
       "      <td>0.168983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Y0          Y1          Y2          Y3          Y4\n",
       "count  107.000000  106.000000  105.000000  104.000000  103.000000\n",
       "mean     0.028037    0.028302    0.028571    0.028846    0.029126\n",
       "std      0.165856    0.166622    0.167398    0.168185    0.168983\n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000\n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Data.loc[ID_Data.SKU==117].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174b9d9-e694-4ad0-8039-219ce4a30b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816dddbf-178a-4add-a043-9d37ddefe915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06cff2-dd5c-4ade-8cf0-83bbba03a22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff221d3-8524-4f2a-9f4c-0e68a844e0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9828a1-0293-4bdb-949d-fb5440c0b446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Initialize preprocessing module\n",
    "    pp = PreProcessing()\n",
    "        \n",
    "    # Select and training data\n",
    "    args = {'train': (ID_Data.sale_yearweek < test_start - tau)}\n",
    "    \n",
    "    id_train = pp.train_test_split(ID_Data, **args)\n",
    "    X_train = pp.train_test_split(X_Data_z, **args, to_array=True)\n",
    "    y_train = pp.train_test_split(Y_Data_z, **args, rolling_horizon=[l for l in range(0,tau+1)], to_array=True)\n",
    "   \n",
    "    # Initialize\n",
    "    weightsmodel = RandomForestWeightsModel(model_params)\n",
    "\n",
    "    # CV search\n",
    "    cv_folds = pp.split_timeseries_cv(n_splits=3, timePeriods=id_train.sale_yearweek)\n",
    "    cv_results = weightsmodel.tune(X_train, y_train, cv_folds, hyper_params_grid, tuning_params, random_search, print_status)\n",
    "    weightsmodel.save_cv_result(path=PATH_WEIGHTSMODEL+'/'+weightsmodel_cv_name+'_tau'+str(tau)+'.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135fff30-5122-4776-a507-85b29f06ecae",
   "metadata": {},
   "source": [
    "#### Fit weight functions and generate weights\n",
    "\n",
    "We now fit the global random forest weights model (i.e., the weight functions) for each $\\tau=0,...,4$ and over periods $t=1,...,T$. This is done across all products at once (global training). Then, for each $\\tau=0,...,4$ and over periods $t=1,...,T$, we generate for each product (SKU) $k=1,...,M$ the weights given the test feature $x_{k,t}$. This is done *jointly* across products (by using $x_{t}=(x_{1,t},...,x_{M,t})^{\\top}$) for computational efficiency - the weights for each individual product can be extracted afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac397b5-6cd1-4b43-82c6-92cc48459b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_params = {\n",
    "    'n_jobs': 32,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e4020-8b86-47b7-92b7-55861cb27f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Initialize\n",
    "    samples, weightfunctions, weightfunctions_times, weights, weights_times = {}, {}, {}, {}, {}\n",
    "        \n",
    "    # For each period t=1,...,T\n",
    "    for t in ts:\n",
    "\n",
    "        # Adjust look-ahead tau to account for end of horizon\n",
    "        tau_ = min(tau,T-t)\n",
    "        \n",
    "        # Status\n",
    "        print('#### Look-ahead tau='+str(tau)+' (tau\\'='+str(tau_)+'), period t='+str(t)+'...')\n",
    "        start_time = dt.datetime.now().replace(microsecond=0)\n",
    "                \n",
    "        # Generate samples, fit weight functions, and generate weights (based on tuned weights model)\n",
    "        weightsmodel = RandomForestWeightsModel()\n",
    "        weightsmodel.load_cv_result(path=PATH_WEIGHTSMODEL+'/'+weightsmodel_cv_name+'_tau'+str(tau_)+'.joblib')\n",
    "        \n",
    "        res = weightsmodel.training_and_sampling2(ID_Data, X_Data, Y_Data, tau=tau_, timePeriods=ID_Data.sale_yearweek,\n",
    "                                                  timePeriodsTestStart=test_start+t-1, model_params=model_params)\n",
    "        samples[t], weightfunctions[t], weightfunctions_times[t], weights[t], weights_times[t] = res\n",
    "        \n",
    "        # Status\n",
    "        print('...done in', dt.datetime.now().replace(microsecond=0) - start_time)    \n",
    "        \n",
    "    # Save\n",
    "    _ = joblib.dump(samples, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')  \n",
    "    _ = joblib.dump(weightfunctions, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weightfunctions_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_times_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_times_tau'+str(tau)+'.joblib')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb286db-6601-471c-8902-5311ccd78a3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a5ac4-f30b-4345-8c0f-70a976174124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e928e14-b77e-4d02-ad27-ecd53b3a9d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Testing with \"old\" hyper params for global RF models ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ee2c809-d6b5-4a56-83d1-d10f31de8721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_global_not_reshaped_old_rf_params'\n",
    "weightsmodel_name = 'rfwm_global_not_reshaped_old_rf_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed444c8f-33da-448f-8cb3-917db5179fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfwm_0 = joblib.load('/home/fesc/DataDrivenDynamicInventoryControl/rf_mv_t1.joblib')\n",
    "rfwm_1 = joblib.load('/home/fesc/DataDrivenDynamicInventoryControl/rf_mv_t2.joblib')\n",
    "rfwm_2 = joblib.load('/home/fesc/DataDrivenDynamicInventoryControl/rf_mv_t3.joblib')\n",
    "rfwm_3 = joblib.load('/home/fesc/DataDrivenDynamicInventoryControl/rf_mv_t4.joblib')\n",
    "rfwm_4 = joblib.load('/home/fesc/DataDrivenDynamicInventoryControl/rf_mv_t5.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "3156770a-3ebc-4e12-8b87-49b8c899969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_params = {\n",
    "    'n_jobs': 96,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "93b18c4c-5375-421e-820e-cf1f5e5cf471",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {}\n",
    "\n",
    "\n",
    "hyper_params[0] = {\n",
    "    \n",
    "    'max_features': 144, \n",
    "    'min_samples_leaf': 10,\n",
    "    'n_estimators': 500,\n",
    "}\n",
    "\n",
    "hyper_params[1] = {\n",
    "    \n",
    "    'max_features': 160, \n",
    "    'min_samples_leaf': 10,\n",
    "    'n_estimators': 500,\n",
    "}\n",
    "\n",
    "hyper_params[2] = {\n",
    "    \n",
    "    'max_features': 96, \n",
    "    'min_samples_leaf': 10,\n",
    "    'n_estimators': 500,\n",
    "}\n",
    "\n",
    "hyper_params[3] = {\n",
    "    \n",
    "    'max_features': 112, \n",
    "    'min_samples_leaf': 10,\n",
    "    'n_estimators': 500,\n",
    "}\n",
    "\n",
    "hyper_params[4] = {\n",
    "    \n",
    "    'max_features': 48, \n",
    "    'min_samples_leaf': 10,\n",
    "    'n_estimators': 500,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed1db13-590b-4f75-9370-2c0ca712b06c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Look-ahead tau=0 (tau'=0), period t=1...\n",
      "...done in 0:01:24\n",
      "#### Look-ahead tau=0 (tau'=0), period t=2...\n",
      "...done in 0:01:28\n",
      "#### Look-ahead tau=0 (tau'=0), period t=3...\n",
      "...done in 0:01:26\n",
      "#### Look-ahead tau=0 (tau'=0), period t=4...\n",
      "...done in 0:01:30\n",
      "#### Look-ahead tau=0 (tau'=0), period t=5...\n",
      "...done in 0:05:12\n",
      "#### Look-ahead tau=0 (tau'=0), period t=6...\n",
      "...done in 0:01:33\n",
      "#### Look-ahead tau=0 (tau'=0), period t=7...\n",
      "...done in 0:01:30\n",
      "#### Look-ahead tau=0 (tau'=0), period t=8...\n",
      "...done in 0:01:35\n",
      "#### Look-ahead tau=0 (tau'=0), period t=9...\n",
      "...done in 0:01:32\n",
      "#### Look-ahead tau=0 (tau'=0), period t=10...\n",
      "...done in 0:01:34\n",
      "#### Look-ahead tau=0 (tau'=0), period t=11...\n",
      "...done in 0:01:35\n",
      "#### Look-ahead tau=0 (tau'=0), period t=12...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=0 (tau'=0), period t=13...\n",
      "...done in 0:01:36\n",
      "#### Look-ahead tau=1 (tau'=1), period t=1...\n",
      "...done in 0:01:32\n",
      "#### Look-ahead tau=1 (tau'=1), period t=2...\n",
      "...done in 0:01:29\n",
      "#### Look-ahead tau=1 (tau'=1), period t=3...\n",
      "...done in 0:01:34\n",
      "#### Look-ahead tau=1 (tau'=1), period t=4...\n",
      "...done in 0:01:33\n",
      "#### Look-ahead tau=1 (tau'=1), period t=5...\n",
      "...done in 0:01:34\n",
      "#### Look-ahead tau=1 (tau'=1), period t=6...\n",
      "...done in 0:05:11\n",
      "#### Look-ahead tau=1 (tau'=1), period t=7...\n",
      "...done in 0:01:35\n",
      "#### Look-ahead tau=1 (tau'=1), period t=8...\n",
      "...done in 0:01:33\n",
      "#### Look-ahead tau=1 (tau'=1), period t=9...\n",
      "...done in 0:01:36\n",
      "#### Look-ahead tau=1 (tau'=1), period t=10...\n",
      "...done in 0:01:33\n",
      "#### Look-ahead tau=1 (tau'=1), period t=11...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=1 (tau'=1), period t=12...\n",
      "...done in 0:01:37\n",
      "#### Look-ahead tau=1 (tau'=0), period t=13...\n",
      "...done in 0:01:34\n",
      "#### Look-ahead tau=2 (tau'=2), period t=1...\n",
      "...done in 0:01:18\n",
      "#### Look-ahead tau=2 (tau'=2), period t=2...\n",
      "...done in 0:01:20\n",
      "#### Look-ahead tau=2 (tau'=2), period t=3...\n",
      "...done in 0:01:18\n",
      "#### Look-ahead tau=2 (tau'=2), period t=4...\n",
      "...done in 0:01:23\n",
      "#### Look-ahead tau=2 (tau'=2), period t=5...\n",
      "...done in 0:01:20\n",
      "#### Look-ahead tau=2 (tau'=2), period t=6...\n",
      "...done in 0:01:25\n",
      "#### Look-ahead tau=2 (tau'=2), period t=7...\n",
      "...done in 0:04:50\n",
      "#### Look-ahead tau=2 (tau'=2), period t=8...\n",
      "...done in 0:01:25\n",
      "#### Look-ahead tau=2 (tau'=2), period t=9...\n",
      "...done in 0:01:24\n",
      "#### Look-ahead tau=2 (tau'=2), period t=10...\n",
      "...done in 0:01:26\n",
      "#### Look-ahead tau=2 (tau'=2), period t=11...\n",
      "...done in 0:01:23\n",
      "#### Look-ahead tau=2 (tau'=1), period t=12...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=2 (tau'=0), period t=13...\n",
      "...done in 0:01:35\n",
      "#### Look-ahead tau=3 (tau'=3), period t=1...\n",
      "...done in 0:01:20\n",
      "#### Look-ahead tau=3 (tau'=3), period t=2...\n",
      "...done in 0:01:21\n",
      "#### Look-ahead tau=3 (tau'=3), period t=3...\n",
      "...done in 0:01:25\n",
      "#### Look-ahead tau=3 (tau'=3), period t=4...\n",
      "...done in 0:01:21\n",
      "#### Look-ahead tau=3 (tau'=3), period t=5...\n",
      "...done in 0:01:25\n",
      "#### Look-ahead tau=3 (tau'=3), period t=6...\n",
      "...done in 0:01:22\n",
      "#### Look-ahead tau=3 (tau'=3), period t=7...\n",
      "...done in 0:01:26\n",
      "#### Look-ahead tau=3 (tau'=3), period t=8...\n",
      "...done in 0:04:16\n",
      "#### Look-ahead tau=3 (tau'=3), period t=9...\n",
      "...done in 0:01:29\n",
      "#### Look-ahead tau=3 (tau'=3), period t=10...\n",
      "...done in 0:01:27\n",
      "#### Look-ahead tau=3 (tau'=2), period t=11...\n",
      "...done in 0:01:25\n",
      "#### Look-ahead tau=3 (tau'=1), period t=12...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=3 (tau'=0), period t=13...\n",
      "...done in 0:01:35\n",
      "#### Look-ahead tau=4 (tau'=4), period t=1...\n",
      "...done in 0:01:08\n",
      "#### Look-ahead tau=4 (tau'=4), period t=2...\n",
      "...done in 0:01:12\n",
      "#### Look-ahead tau=4 (tau'=4), period t=3...\n",
      "...done in 0:01:11\n",
      "#### Look-ahead tau=4 (tau'=4), period t=4...\n",
      "...done in 0:01:14\n",
      "#### Look-ahead tau=4 (tau'=4), period t=5...\n",
      "...done in 0:01:12\n",
      "#### Look-ahead tau=4 (tau'=4), period t=6...\n",
      "...done in 0:01:14\n",
      "#### Look-ahead tau=4 (tau'=4), period t=7...\n",
      "...done in 0:01:14\n",
      "#### Look-ahead tau=4 (tau'=4), period t=8...\n",
      "...done in 0:01:17\n",
      "#### Look-ahead tau=4 (tau'=4), period t=9...\n",
      "...done in 0:04:31\n",
      "#### Look-ahead tau=4 (tau'=3), period t=10...\n",
      "...done in 0:01:28\n",
      "#### Look-ahead tau=4 (tau'=2), period t=11...\n",
      "...done in 0:01:24\n",
      "#### Look-ahead tau=4 (tau'=1), period t=12...\n",
      "...done in 0:01:38\n",
      "#### Look-ahead tau=4 (tau'=0), period t=13...\n",
      "...done in 0:01:33\n"
     ]
    }
   ],
   "source": [
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Initialize\n",
    "    samples, weightfunctions, weightfunctions_times, weights, weights_times = {}, {}, {}, {}, {}\n",
    "        \n",
    "    # For each period t=1,...,T\n",
    "    for t in ts:\n",
    "\n",
    "        # Adjust look-ahead tau to account for end of horizon\n",
    "        tau_ = min(tau,T-t)\n",
    "        \n",
    "        # Status\n",
    "        print('#### Look-ahead tau='+str(tau)+' (tau\\'='+str(tau_)+'), period t='+str(t)+'...')\n",
    "        start_time = dt.datetime.now().replace(microsecond=0)\n",
    "                \n",
    "        # Generate samples, fit weight functions, and generate weights (based on tuned weights model)\n",
    "        weightsmodel = RandomForestWeightsModel(hyper_params=hyper_params[tau_])\n",
    "        \n",
    "        res = weightsmodel.training_and_sampling2(ID_Data, X_Data, Y_Data, tau=tau_, timePeriods=ID_Data.sale_yearweek,\n",
    "                                                  timePeriodsTestStart=test_start+t-1, model_params=model_params)\n",
    "        samples[t], weightfunctions[t], weightfunctions_times[t], weights[t], weights_times[t] = res\n",
    "        \n",
    "        # Status\n",
    "        print('...done in', dt.datetime.now().replace(microsecond=0) - start_time)    \n",
    "        \n",
    "    # Save\n",
    "    _ = joblib.dump(samples, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')  \n",
    "    _ = joblib.dump(weightfunctions, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weightfunctions_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_times_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_times_tau'+str(tau)+'.joblib')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c556e2-455a-484d-a8d6-f79290277929",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why does it take longer for t=5 (tau=0)?? Check for other tau's... is there a data issue?\n",
    "\n",
    "# tau=0, t=5\n",
    "# tau=1, t=6\n",
    "# tau=2, t=7\n",
    "# tau=3, t=8\n",
    "# tau=4, t=9\n",
    "\n",
    "# ... what is happening here??\n",
    "\n",
    "# it happends when t-tau == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0e5d0-1b59-4883-bfae-a9a9709b5db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3644f35-b7e7-4dce-8e97-3a93c5c34132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "0a22f220-3a55-439b-a5b5-de4df52bc8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RESHAPED WITH OLD HYPER PARAMS AND SCALING\n",
    "weightsmodel_name = 'rfwm_global_r_z_old_hyper_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "964cee34-ebba-409e-9937-41ed3070b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Look-ahead tau=0 (tau'=0), period t=1...\n",
      "...done in 0:02:13\n",
      "#### Look-ahead tau=0 (tau'=0), period t=2...\n",
      "...done in 0:02:18\n",
      "#### Look-ahead tau=0 (tau'=0), period t=3...\n",
      "...done in 0:02:16\n",
      "#### Look-ahead tau=0 (tau'=0), period t=4...\n",
      "...done in 0:02:19\n",
      "#### Look-ahead tau=0 (tau'=0), period t=5...\n",
      "...done in 0:05:43\n",
      "#### Look-ahead tau=0 (tau'=0), period t=6...\n",
      "...done in 0:02:22\n",
      "#### Look-ahead tau=0 (tau'=0), period t=7...\n",
      "...done in 0:02:19\n",
      "#### Look-ahead tau=0 (tau'=0), period t=8...\n",
      "...done in 0:02:22\n",
      "#### Look-ahead tau=0 (tau'=0), period t=9...\n",
      "...done in 0:02:20\n",
      "#### Look-ahead tau=0 (tau'=0), period t=10...\n",
      "...done in 0:02:24\n",
      "#### Look-ahead tau=0 (tau'=0), period t=11...\n",
      "...done in 0:02:23\n",
      "#### Look-ahead tau=0 (tau'=0), period t=12...\n",
      "...done in 0:02:27\n",
      "#### Look-ahead tau=0 (tau'=0), period t=13...\n",
      "...done in 0:02:22\n",
      "#### Look-ahead tau=1 (tau'=1), period t=1...\n",
      "...done in 0:01:34\n",
      "#### Look-ahead tau=1 (tau'=1), period t=2...\n",
      "...done in 0:01:32\n",
      "#### Look-ahead tau=1 (tau'=1), period t=3...\n",
      "...done in 0:01:34\n",
      "#### Look-ahead tau=1 (tau'=1), period t=4...\n",
      "...done in 0:01:34\n",
      "#### Look-ahead tau=1 (tau'=1), period t=5...\n",
      "...done in 0:01:35\n",
      "#### Look-ahead tau=1 (tau'=1), period t=6...\n",
      "...done in 0:01:36\n",
      "#### Look-ahead tau=1 (tau'=1), period t=7...\n",
      "...done in 0:01:36\n",
      "#### Look-ahead tau=1 (tau'=1), period t=8...\n",
      "...done in 0:01:37\n",
      "#### Look-ahead tau=1 (tau'=1), period t=9...\n",
      "...done in 0:01:38\n",
      "#### Look-ahead tau=1 (tau'=1), period t=10...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=1 (tau'=1), period t=11...\n",
      "...done in 0:01:38\n",
      "#### Look-ahead tau=1 (tau'=1), period t=12...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=1 (tau'=0), period t=13...\n",
      "...done in 0:02:24\n",
      "#### Look-ahead tau=2 (tau'=2), period t=1...\n",
      "...done in 0:01:15\n",
      "#### Look-ahead tau=2 (tau'=2), period t=2...\n",
      "...done in 0:01:13\n",
      "#### Look-ahead tau=2 (tau'=2), period t=3...\n",
      "...done in 0:01:14\n",
      "#### Look-ahead tau=2 (tau'=2), period t=4...\n",
      "...done in 0:01:14\n",
      "#### Look-ahead tau=2 (tau'=2), period t=5...\n",
      "...done in 0:01:15\n",
      "#### Look-ahead tau=2 (tau'=2), period t=6...\n",
      "...done in 0:01:15\n",
      "#### Look-ahead tau=2 (tau'=2), period t=7...\n",
      "...done in 0:01:17\n",
      "#### Look-ahead tau=2 (tau'=2), period t=8...\n",
      "...done in 0:01:16\n",
      "#### Look-ahead tau=2 (tau'=2), period t=9...\n",
      "...done in 0:01:16\n",
      "#### Look-ahead tau=2 (tau'=2), period t=10...\n",
      "...done in 0:01:14\n",
      "#### Look-ahead tau=2 (tau'=2), period t=11...\n",
      "...done in 0:01:16\n",
      "#### Look-ahead tau=2 (tau'=1), period t=12...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=2 (tau'=0), period t=13...\n",
      "...done in 0:02:24\n",
      "#### Look-ahead tau=3 (tau'=3), period t=1...\n",
      "...done in 0:01:08\n",
      "#### Look-ahead tau=3 (tau'=3), period t=2...\n",
      "...done in 0:01:08\n",
      "#### Look-ahead tau=3 (tau'=3), period t=3...\n",
      "...done in 0:01:09\n",
      "#### Look-ahead tau=3 (tau'=3), period t=4...\n",
      "...done in 0:01:08\n",
      "#### Look-ahead tau=3 (tau'=3), period t=5...\n",
      "...done in 0:01:09\n",
      "#### Look-ahead tau=3 (tau'=3), period t=6...\n",
      "...done in 0:01:10\n",
      "#### Look-ahead tau=3 (tau'=3), period t=7...\n",
      "...done in 0:01:10\n",
      "#### Look-ahead tau=3 (tau'=3), period t=8...\n",
      "...done in 0:01:11\n",
      "#### Look-ahead tau=3 (tau'=3), period t=9...\n",
      "...done in 0:01:10\n",
      "#### Look-ahead tau=3 (tau'=3), period t=10...\n",
      "...done in 0:01:09\n",
      "#### Look-ahead tau=3 (tau'=2), period t=11...\n",
      "...done in 0:01:17\n",
      "#### Look-ahead tau=3 (tau'=1), period t=12...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=3 (tau'=0), period t=13...\n",
      "...done in 0:02:26\n",
      "#### Look-ahead tau=4 (tau'=4), period t=1...\n",
      "...done in 0:01:04\n",
      "#### Look-ahead tau=4 (tau'=4), period t=2...\n",
      "...done in 0:01:04\n",
      "#### Look-ahead tau=4 (tau'=4), period t=3...\n",
      "...done in 0:01:04\n",
      "#### Look-ahead tau=4 (tau'=4), period t=4...\n",
      "...done in 0:01:05\n",
      "#### Look-ahead tau=4 (tau'=4), period t=5...\n",
      "...done in 0:01:03\n",
      "#### Look-ahead tau=4 (tau'=4), period t=6...\n",
      "...done in 0:01:05\n",
      "#### Look-ahead tau=4 (tau'=4), period t=7...\n",
      "...done in 0:01:03\n",
      "#### Look-ahead tau=4 (tau'=4), period t=8...\n",
      "...done in 0:01:05\n",
      "#### Look-ahead tau=4 (tau'=4), period t=9...\n",
      "...done in 0:01:05\n",
      "#### Look-ahead tau=4 (tau'=3), period t=10...\n",
      "...done in 0:01:10\n",
      "#### Look-ahead tau=4 (tau'=2), period t=11...\n",
      "...done in 0:01:17\n",
      "#### Look-ahead tau=4 (tau'=1), period t=12...\n",
      "...done in 0:01:39\n",
      "#### Look-ahead tau=4 (tau'=0), period t=13...\n",
      "...done in 0:02:25\n"
     ]
    }
   ],
   "source": [
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Initialize\n",
    "    samples, weightfunctions, weightfunctions_times, weights, weights_times = {}, {}, {}, {}, {}\n",
    "        \n",
    "    # For each period t=1,...,T\n",
    "    for t in ts:\n",
    "\n",
    "        # Adjust look-ahead tau to account for end of horizon\n",
    "        tau_ = min(tau,T-t)\n",
    "        \n",
    "        # Status\n",
    "        print('#### Look-ahead tau='+str(tau)+' (tau\\'='+str(tau_)+'), period t='+str(t)+'...')\n",
    "        start_time = dt.datetime.now().replace(microsecond=0)\n",
    "                \n",
    "        # Generate samples, fit weight functions, and generate weights (based on tuned weights model)\n",
    "        weightsmodel = RandomForestWeightsModel(hyper_params=hyper_params[tau_])\n",
    "        \n",
    "        # Preprocess features\n",
    "        X_Data_z = copy.deepcopy(X_Data)\n",
    "        features_to_scale = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].Feature\n",
    "        features_to_scale_with = X_Data_Columns.loc[X_Data_Columns.Scale == 'YES'].ScaleWith\n",
    "\n",
    "        for SKU in SKUs:\n",
    "            for feature_to_scale, feature_to_scale_with in zip(features_to_scale, features_to_scale_with):\n",
    "\n",
    "                X_Data_z.loc[ID_Data.SKU == SKU, feature_to_scale] = (\n",
    "                    X_Data.loc[ID_Data.SKU == SKU][feature_to_scale] / x_scalers[t][SKU].scalers[feature_to_scale_with]\n",
    "                )\n",
    "                \n",
    "        # Preprocess demands\n",
    "        Y_Data_z = copy.deepcopy(Y_Data)\n",
    "\n",
    "        for SKU in SKUs:\n",
    "            Y_Data_z.loc[ID_Data.SKU == SKU] = (\n",
    "                Y_Data.loc[ID_Data.SKU == SKU] / y_scalers[t][SKU].scalers[0]\n",
    "            )\n",
    "\n",
    "        res = weightsmodel.training_and_sampling(ID_Data, X_Data_z, Y_Data_z, tau=tau_, timePeriods=ID_Data.sale_yearweek,\n",
    "                                                 timePeriodsTestStart=test_start+t-1, model_params=model_params)\n",
    "        samples[t], weightfunctions[t], weightfunctions_times[t], weights[t], weights_times[t] = res\n",
    "        \n",
    "        # Status\n",
    "        print('...done in', dt.datetime.now().replace(microsecond=0) - start_time)    \n",
    "        \n",
    "    # Save\n",
    "    _ = joblib.dump(samples, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')  \n",
    "    _ = joblib.dump(weightfunctions, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weightfunctions_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_times_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_times_tau'+str(tau)+'.joblib')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ad5102-f3b8-4cb2-83b3-2e4bbc1a3329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67402446-6fd7-41d0-ae56-3dbe12d1a187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9458d3a-6f80-48e3-af26-e587ddc8354f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8087404f-b274-4a9a-a1d0-c30d4c7cf38e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043dfde-0de3-4810-9810-88b9492c4899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a8b80-e988-4fc3-bebf-72568a45b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f6f1b-0440-4c6e-ad66-174d8451b017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e739223-1511-4e45-90ac-8200e53decc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ed8131-7c14-4331-ab7e-239d3cf2b8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c109b-a958-4789-ac3b-328c38d3d378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d357c25-392d-4686-be11-9fd8a580f007",
   "metadata": {},
   "source": [
    "## Local Training and Sampling\n",
    "\n",
    "The two local models (using 'Local Training and Sampling') are **Rolling Horizon Local Weighted SAA (wSAA)**, and **Rolling Horizon Local Robust Weighted SAA (wSAA-R)**, which is the analogous model with robust extension.\n",
    "\n",
    "Given product $k$, period $t$, and look-ahead $\\tau$, both models apply Weighted SAA over the 'local' distribution $\\{w_{k,t,\\tau}^{\\,i}(x_{k,t}^{\\,i}),(d_{k,t}^{\\,i},...,d_{k,t+\\tau}^{\\,i})\\}_{i=1}^{N_{k,t,\\tau}}$, with weight functions $w_{k,t,\\tau}(\\,\\cdot\\,)$ trained on data $S_{k,t,\\tau}^{\\,\\text{Local}}=\\{(x_{k,t}^{\\,i},d_{k,t}^{\\,i},...,d_{k,t+\\tau}^{\\,i})\\}_{i=1}^{N_{k,t,\\tau}}$ for each product $k=1,...,M$ separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1793967-c0a7-49f9-afbe-3c2edc82a733",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "We first load and pre-process the data. This includes reshaping demand time series into $(\\tau+1)$-periods rolling look-ahead horizon sequences.\n",
    "\n",
    "- **ID_Data** (pd.DataFrame) stores identifiers (in particular the product (SKU) identifier and the timePeriod (sale_yearweek) identifier)\n",
    "- **X_Data** (pd.DataFrame) is the 'feature matrix', i.e., each row is a feature vector $x_{j,n}$ where n is the number of training observations (rows) in the data\n",
    "- **Y_Data** (pd.DataFrame) is the demand data $d_{j,n}$ (a times series per product)\n",
    "- **X_Data_Columns** (pd.DataFrame) provides 'selectors' for local vs. global feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "91cde388-4e04-432e-a25f-c7c86ad4a54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_local_r'\n",
    "weightsmodel_name = 'rfwm_local_r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "id": "ed0c111f-7ccb-4ddb-aa74-41e9c671bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "ID_Data = pd.read_csv(PATH_DATA+'/ID_Data.csv')\n",
    "X_Data = pd.read_csv(PATH_DATA+'/X_Data.csv')\n",
    "X_Data_Columns = pd.read_csv(PATH_DATA+'/X_Data_Columns4.csv')\n",
    "Y_Data = pd.read_csv(PATH_DATA+'/Y_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "598a27ac-fb86-4586-97e1-04fb33da5f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features\n",
    "X_Data_Columns = X_Data_Columns.loc[X_Data_Columns.Local == 'YES']\n",
    "X_Data = X_Data[X_Data_Columns.Feature.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "badda3cf-e799-4d46-9fcf-af3ec6dac26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure data is sorted by SKU and sale_yearweek for preprocessing\n",
    "data = pd.concat([ID_Data, X_Data, Y_Data], axis=1).sort_values(by=['SKU', 'sale_yearweek']).reset_index(drop=True)\n",
    "\n",
    "ID_Data = data[ID_Data.columns]\n",
    "X_Data = data[X_Data.columns]\n",
    "Y_Data = data[Y_Data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "f2044675-b66d-42d9-ab1d-24cd56e81dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multi-period demand vectors\n",
    "data = pd.concat([ID_Data, Y_Data], axis=1)\n",
    "Y = {}\n",
    "for tau in taus:\n",
    "    Y['Y'+str(tau)] = data.groupby(['SKU']).shift(-tau)['Y']\n",
    "Y_Data = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be213da-406b-4e42-8699-2f5973a9c767",
   "metadata": {},
   "source": [
    "### Weights model\n",
    "\n",
    "The weights model - and thus the data used, weight functions, and weights per sample - are the same for the two local models **wSAA** and **wSAA-R**. First, we tune the hyper parameters of the random forest weights model for each given look-ahead $\\tau$ (as for each look-ahead $\\tau$ we have a different response for the multi-output random forest regressor) and for each product (SKU) $k=1,...,M$ separately. Second, we fit all weight functions (for each look-ahead $\\tau=0,...,4$ and over periods $t=1,...,T$) for each product (SKU) $k=1,...,M$ separately and generate all weights (for each look-ahead $\\tau=0,...,4$, over periods $t=1,...,T$, and for each product (SKU) $k=1,...,M$ separatey)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0442f-cdaa-47ad-a691-4b2aac018b30",
   "metadata": {},
   "source": [
    "#### Tune weights model\n",
    "\n",
    "To tune the hyper parameters of the local random forest weights model for each product (SKU) $k=1,...,M$, we use 3-fold rolling timeseries cross-validation on the training data and perform random search with 100 iterations over the specified hyper parameter search grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "26653420-33b5-4569-8397-2da1590e53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters to tune random forest weights kernels\n",
    "model_params = {\n",
    "    'oob_score': True,\n",
    "    'random_state': 12345,\n",
    "    'n_jobs': 1,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "hyper_params_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [x for x in range(2, 20, 1)],  \n",
    "    'min_samples_leaf': [x for x in range(2, 10, 1)],  \n",
    "    'max_features': [x for x in range(8, 256, 8)],   \n",
    "    'max_leaf_nodes': [None],\n",
    "    'min_impurity_decrease': [0.0],\n",
    "    'bootstrap': [True],\n",
    "    'max_samples': [0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "}    \n",
    "\n",
    "\n",
    "tuning_params = {     \n",
    "    'n_iter': 100,\n",
    "    'scoring': {'MSE': 'neg_mean_squared_error'},\n",
    "    'return_train_score': True,\n",
    "    'refit': 'MSE',\n",
    "    'random_state': 12345,\n",
    "    'n_jobs': 32,\n",
    "    'verbose': 0\n",
    "}    \n",
    "\n",
    "random_search = True\n",
    "print_status = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c381d48c-ccee-44df-9335-7595ae2c48f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Status\n",
    "    print('Look-ahead tau='+str(tau)+'...')\n",
    "    start_time = dt.datetime.now().replace(microsecond=0)\n",
    "    \n",
    "    # Initialize\n",
    "    cv_results = {}\n",
    "    \n",
    "    # For each product (SKU) k=1,...,M\n",
    "    for SKU in SKUs:\n",
    "\n",
    "        # Initialize preprocessing module\n",
    "        pp = PreProcessing()\n",
    "\n",
    "        # Select and reshape training and test data\n",
    "        args = {'train': (ID_Data.SKU == SKU) & (ID_Data.sale_yearweek < test_start - tau)}\n",
    "\n",
    "        # id_train = pp.train_test_split2(ID_Data, **args)\n",
    "        # X_train = pp.train_test_split2(X_Data, **args, to_array=True)\n",
    "        # y_train = pp.train_test_split2(Y_Data, **args, rolling_horizon=[l for l in range(0,tau+1)], to_array=True)\n",
    "        \n",
    "        \n",
    "        id_train = pp.train_test_split(ID_Data, **args)\n",
    "        X_train = pp.train_test_split(X_Data, **args, to_array=True)\n",
    "        y_train = pp.train_test_split(Y_Data, **args, rolling_horizon=[l for l in range(0,tau+1)], to_array=True)\n",
    "\n",
    "        # Initialize\n",
    "        weightsmodel = RandomForestWeightsModel(model_params)\n",
    "\n",
    "        # CV search\n",
    "        cv_folds = pp.split_timeseries_cv(n_splits=3, timePeriods=id_train.sale_yearweek)\n",
    "        cv_results[SKU] = weightsmodel.tune(X_train, y_train, cv_folds, hyper_params_grid, \n",
    "                                            tuning_params, random_search, print_status)\n",
    "        \n",
    "        # Status\n",
    "        print('SKU '+str(SKU)+' of '+str(len(SKUs))+' in', dt.datetime.now().replace(microsecond=0) - start_time, end='\\r', flush=True)\n",
    "\n",
    "    # Save\n",
    "    _ = joblib.dump(cv_results, PATH_WEIGHTSMODEL+'/'+weightsmodel_cv_name+'_tau'+str(tau)+'.joblib')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f1c7a-4494-4191-858a-231dc1ba9fd0",
   "metadata": {},
   "source": [
    "#### Fit weight functions and generate weights\n",
    "\n",
    "We now fit a local random forest weights model (i.e., the weight functions) for each $\\tau=0,...,4$, period $t=1,...,T$, and product (SKU) $k=1,...,M$ separately (local training). Then, for each $\\tau=0,...,4$, period $t=1,...,T$, and product (SKU) $k=1,...,M$ separately, we generate the weights given the test feature $x_{k,t}$. This is done *separately* for each product (SKU) $k=1,...,M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410060e-ec5e-4f5d-8da2-7a81da076ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "model_params = {\n",
    "    'n_jobs': 32,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print_status = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f806721b-465b-4edf-b312-a88245d9b425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Status\n",
    "    print('Look-ahead tau='+str(tau)+'...')\n",
    "    start_time = dt.datetime.now().replace(microsecond=0)\n",
    "    \n",
    "    # Initialize\n",
    "    samples, weightfunctions, weightfunctions_times, weights, weights_times = {}, {}, {}, {}, {}\n",
    "    \n",
    "    # For each product (SKU) k=1,...,M\n",
    "    for SKU in SKUs:\n",
    "        \n",
    "        # Initialize\n",
    "        samples[SKU], weightfunctions[SKU], weightfunctions_times[SKU], weights[SKU], weights_times[SKU] = {}, {}, {}, {}, {}\n",
    "        \n",
    "        # For each period t=1,...,T\n",
    "        for t in ts:\n",
    "        \n",
    "            # Adjust look-ahead tau to account for end of horizon\n",
    "            tau_ = min(tau,T-t)\n",
    "\n",
    "            # Generate samples, fit weight functions, and generate weights (based on tuned weights model)\n",
    "            weightsmodel = RandomForestWeightsModel()\n",
    "            weightsmodel.load_cv_result(path=PATH_WEIGHTSMODEL+'/'+weightsmodel_cv_name+'_tau'+str(tau_)+'.joblib', SKU=SKU)\n",
    "            res = weightsmodel.training_and_sampling(ID_Data.loc[ID_Data.SKU==SKU], X_Data.loc[ID_Data.SKU==SKU], Y_Data.loc[ID_Data.SKU==SKU], \n",
    "                                                     tau=tau_, timePeriods=ID_Data.loc[ID_Data.SKU==SKU].sale_yearweek, \n",
    "                                                     timePeriodsTestStart=test_start+t-1, model_params=model_params)\n",
    "            samples[SKU][t], weightfunctions[SKU][t], weightfunctions_times[SKU][t], weights[SKU][t], weights_times[SKU][t] = res\n",
    "\n",
    "        # Status\n",
    "        print('SKU '+str(SKU)+' of '+str(len(SKUs))+' in', dt.datetime.now().replace(microsecond=0) - start_time, end='\\r', flush=True)\n",
    "        \n",
    "    # Save\n",
    "    _ = joblib.dump(samples, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')  \n",
    "    _ = joblib.dump(weightfunctions, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weightfunctions_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weightfunctions_times_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')    \n",
    "    _ = joblib.dump(weights_times, PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_times_tau'+str(tau)+'.joblib')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f17b3f0-3b89-4b50-bf05-4ff9e354f56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32c5382-2068-4a23-ab8f-dd0a8099cab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6d6e9-a0b8-4a8a-9af5-9b69f3ecc8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### RESHAPED #####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18a62e-a6ee-4574-ab58-6b508bb5aa60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc0162-892b-457d-8324-808a9ec7796c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4df65-7215-4e79-b44e-8e4f2d9925bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba764f-24b1-43ef-8fde-39ef29e55cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c746bbca-95cd-4012-a2ae-643beb38d019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24af6eba-d18e-4571-bf48-774160b7ee3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edca9986-993c-4b9a-96e5-22444655a258",
   "metadata": {},
   "source": [
    "# Rolling Horizon Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8e28f-3903-447f-b538-a0b937c26688",
   "metadata": {},
   "source": [
    "The code below runs an experiment for all given products (SKUs) $k=1,...,M$ over a test planning horizon $t=1,...,T$ with $T=13$ for three different cost parameter settings $\\{K, u, h, b\\}$ that vary the critical ratio ($CR=\\frac{b}{b+h}$) of holding and backlogging yielding\n",
    "- $CR=0.50$: $\\{K=100, u=0.5, h=1, b=1\\}$\n",
    "- $CR=0.75$: $\\{K=100, u=0.5, h=1, b=3\\}$\n",
    "- $CR=0.90$: $\\{K=100, u=0.5, h=1, b=9\\}$\n",
    "\n",
    "We run experiments for different choices of the look-ahead $\\tau=0,...,4$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d2455-3d8d-48f6-bee1-386b8cd57dbf",
   "metadata": {},
   "source": [
    "## Experiment functions\n",
    "\n",
    "We first define several functions for experiments over different choices for the look-ahead $\\tau=0,...,4$, cost parameter settings $\\{K,u,h,b\\}$, products (SKUs) $k=1,...,M$, and periods $t=1,...,T$ of the planning horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "af4fdf63-45bb-4295-a7da-7d2677960c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to extract global historical demand samples, weights, and actuals for each product and test period\n",
    "def prep_samples_and_weights(samples, weights=None, e=None, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    SKUs = kwargs.get('SKUs', range(1,460+1))\n",
    "    ts = kwargs.get('ts', range(1,13+1))\n",
    "    \n",
    "    # Local\n",
    "    if len(samples) == len(SKUs):\n",
    "        \n",
    "        # Samples\n",
    "        samples_ = {}\n",
    "        for SKU in SKUs:\n",
    "            samples_[SKU] = {}\n",
    "            for t in ts:\n",
    "                samples_[SKU][t] = samples[SKU][t]['y_train']\n",
    "                \n",
    "        # Actuals\n",
    "        actuals_ = {}\n",
    "        for SKU in SKUs:\n",
    "            actuals_[SKU] = {}\n",
    "            for t in ts:\n",
    "                actuals_[SKU][t] = samples[SKU][t]['y_test'].flatten()\n",
    "                \n",
    "        # Weights   \n",
    "        if not weights is None:\n",
    "            weights_ = {}\n",
    "            for SKU in SKUs:\n",
    "                weights_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    weights_[SKU][t] = weights[SKU][t].flatten()\n",
    "                    \n",
    "        # Epsilons\n",
    "        if not e is None:\n",
    "            epsilons_ = {}\n",
    "            for SKU in SKUs:\n",
    "                epsilons_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    epsilons_[SKU][t] = e*np.std(samples[SKU][t]['y_train'], axis=0).flatten()[0]\n",
    "                 \n",
    "    # Global\n",
    "    else:\n",
    "        \n",
    "        # Samples\n",
    "        samples_ = {}\n",
    "        for t in ts:\n",
    "            samples_[t] = samples[t]['y_train']\n",
    "\n",
    "        # Actuals\n",
    "        actuals_ = {}\n",
    "        for SKU in SKUs:\n",
    "            actuals_[SKU] = {}\n",
    "            for t in ts:\n",
    "                actuals_[SKU][t] = samples[t]['y_test'][samples[t]['id_test'].SKU==SKU].flatten()\n",
    "\n",
    "        # Weights   \n",
    "        if not weights is None:\n",
    "            weights_ = {}\n",
    "            for SKU in SKUs:\n",
    "                weights_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    weights_[SKU][t] = weights[t][samples[t]['id_test'].SKU==SKU].flatten()\n",
    "                    \n",
    "        # Epsilons\n",
    "        if not e is None:\n",
    "            epsilons_ = {}\n",
    "            for SKU in SKUs:\n",
    "                epsilons_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    epsilons_[SKU][t] = e*np.std(samples[t]['y_train'][samples[t]['id_train'].SKU == SKU], axis=0).flatten()[0]\n",
    "\n",
    "    # Return\n",
    "    if not weights is None:\n",
    "        if not e is None:\n",
    "            return samples_, actuals_, weights_, epsilons_\n",
    "        else:\n",
    "            return samples_, actuals_, weights_\n",
    "    else:\n",
    "        if not e is None:\n",
    "            return samples_, actuals_, epsilons_\n",
    "        else:\n",
    "            return samples_, actuals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "f0f81083-76cb-4635-913a-c6e8d9912bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to extract global historical demand samples, weights, and actuals for each product and test period\n",
    "def prep_samples_and_weights(samples, weights=None, e=None, scalers=None, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    ...\n",
    "        \n",
    "    if scalers is provided, rescales ...\n",
    "    \n",
    "    if e is provided, generates epsilons (based on rescaled data if scalers is provided ...\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    SKUs = kwargs.get('SKUs', range(1,460+1))\n",
    "    ts = kwargs.get('ts', range(1,13+1))\n",
    "           \n",
    "            \n",
    "    # Local\n",
    "    if len(samples) == len(SKUs):\n",
    "        \n",
    "        # Samples\n",
    "        samples_ = {}\n",
    "        for SKU in SKUs:\n",
    "            samples_[SKU] = {}\n",
    "            for t in ts:\n",
    "                samples_[SKU][t] = samples[SKU][t]['y_train']\n",
    "                \n",
    "        # Actuals\n",
    "        actuals_ = {}\n",
    "        for SKU in SKUs:\n",
    "            actuals_[SKU] = {}\n",
    "            for t in ts:\n",
    "                actuals_[SKU][t] = samples[SKU][t]['y_test'].flatten()\n",
    "                \n",
    "        # Weights   \n",
    "        if not weights is None:\n",
    "            weights_ = {}\n",
    "            for SKU in SKUs:\n",
    "                weights_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    weights_[SKU][t] = weights[SKU][t].flatten()\n",
    "                    \n",
    "        # Epsilons\n",
    "        if not e is None:\n",
    "            epsilons_ = {}\n",
    "            for SKU in SKUs:\n",
    "                epsilons_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    y_train = samples[SKU][t]['y_train'].flatten()\n",
    "                    epsilons_[SKU][t] = e*np.std(y_train)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                 \n",
    "    # Global\n",
    "    else:\n",
    "        \n",
    "        # Samples - rescaling\n",
    "        if not scalers is None:\n",
    "            \n",
    "            samples_ = {}\n",
    "            for SKU in SKUs:\n",
    "                samples_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    samples_[SKU][t] = samples[t]['y_train'] * scalers[t][SKU].scalers[0]            \n",
    "            \n",
    "        # Samples\n",
    "        else:\n",
    "            \n",
    "            samples_ = {}\n",
    "            for t in ts:\n",
    "                samples_[t] = samples[t]['y_train']\n",
    "\n",
    "        # Actuals - rescaling\n",
    "        if not scalers is None:\n",
    "            \n",
    "            actuals_ = {}\n",
    "            for SKU in SKUs:\n",
    "                actuals_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    actuals_[SKU][t] = samples[t]['y_test'][samples[t]['id_test'].SKU==SKU].flatten() * scalers[t][SKU].scalers[0]\n",
    "            \n",
    "        # Actuals\n",
    "        else:\n",
    "            \n",
    "            actuals_ = {}\n",
    "            for SKU in SKUs:\n",
    "                actuals_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    actuals_[SKU][t] = samples[t]['y_test'][samples[t]['id_test'].SKU==SKU].flatten()\n",
    "\n",
    "        # Weights   \n",
    "        if not weights is None:\n",
    "            weights_ = {}\n",
    "            for SKU in SKUs:\n",
    "                weights_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    weights_[SKU][t] = weights[t][samples[t]['id_test'].SKU==SKU].flatten()\n",
    "                    \n",
    "        # Epsilons - rescaling\n",
    "        if (not e is None) and (not scalers is None):\n",
    "            \n",
    "            epsilons_ = {}\n",
    "            for SKU in SKUs:\n",
    "                epsilons_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    y_train = samples[t]['y_train'][samples[t]['id_train'].SKU == SKU].flatten() * scalers[t][SKU].scalers[0]\n",
    "                    epsilons_[SKU][t] = e*np.std(y_train)\n",
    "            \n",
    "        # Epsilons\n",
    "        elif (not e is None) and (scalers is None):\n",
    "            \n",
    "            epsilons_ = {}\n",
    "            for SKU in SKUs:\n",
    "                epsilons_[SKU] = {}\n",
    "                for t in ts:\n",
    "                    y_train = samples[t]['y_train'][samples[t]['id_train'].SKU == SKU].flatten()\n",
    "                    epsilons_[SKU][t] = e*np.std(y_train)\n",
    "\n",
    "    # Return\n",
    "    if not weights is None:\n",
    "        if not e is None:\n",
    "            return samples_, actuals_, weights_, epsilons_\n",
    "        else:\n",
    "            return samples_, actuals_, weights_\n",
    "    else:\n",
    "        if not e is None:\n",
    "            return samples_, actuals_, epsilons_\n",
    "        else:\n",
    "            return samples_, actuals_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "e79cbea7-83af-414e-82f7-95760fd1ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to run an experiment over a list of given cost parameter settings and the specified model\n",
    "def run_experiment(wsaamodel, cost_params, actuals, samples=None, weights=None, epsilons=None, print_progress=False,\n",
    "                   path_to_save=None, name_to_save=None, return_results=True, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Raise error if cost_params is not a list of dict(s)\n",
    "    if not type(cost_params)==list:\n",
    "        raise ValueError('Argument cost_params has to be a list of at least one dict with keys {K, u, h, b}')  \n",
    "    \n",
    "    # Timer\n",
    "    st_exec, st_cpu = time.time(), time.process_time()\n",
    "\n",
    "    # Status\n",
    "    if print_progress and 'SKU' in kwargs: print('SKU:', kwargs['SKU'])\n",
    "    \n",
    "    # Initialize\n",
    "    ropt, results = RollingHorizonOptimization(), pd.DataFrame()\n",
    "\n",
    "    # For each cost param setting\n",
    "    for cost_params_ in cost_params:\n",
    "\n",
    "        # Print progress\n",
    "        if print_progress: print('...cost param setting:', cost_params_)\n",
    "        \n",
    "        # Check if samples provided\n",
    "        if not samples is None:\n",
    "            \n",
    "            # Apply (Weighted) SAA  model\n",
    "            wsaamodel.set_params(**{**kwargs, **cost_params_})\n",
    "            result = ropt.run(wsaamodel, samples, actuals, weights, epsilons)\n",
    "             \n",
    "            # Get T\n",
    "            T = len(samples)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # Apply ex-post clairvoyant model\n",
    "            wsaamodel.set_params(**{**kwargs, **cost_params_})\n",
    "            result = ropt.run_expost(wsaamodel, actuals)\n",
    "            \n",
    "            # Get T\n",
    "            T = actuals.shape[1]\n",
    "\n",
    "        # Store results\n",
    "        meta = pd.DataFrame({'CR': cost_params_['CR'], **kwargs}, index=list(range(T)))\n",
    "        results = pd.concat([results, pd.concat([meta, result], axis=1)], axis=0)\n",
    "\n",
    "    # Save result as csv file\n",
    "    if not path_to_save is None and not name_to_save is None:\n",
    "        results.to_csv(path_or_buf=(path_to_save+'/'+name_to_save+'_SKU'+str(kwargs.get('SKU', None))+\n",
    "                                    '_tau'+str(kwargs.get('tau', None))+'.csv'), sep=',', index=False)\n",
    "\n",
    "    # Timer\n",
    "    exec_time_sec, cpu_time_sec = time.time() - st_exec, time.process_time() - st_cpu\n",
    "    \n",
    "    # Status\n",
    "    if print_progress: print('>>>> Done:', str(np.around(exec_time_sec/60,1)), 'minutes')\n",
    "\n",
    "    # Return  \n",
    "    return results if return_results else {'SKU': kwargs.get('SKU', None), 'exec_time_sec': exec_time_sec, 'cpu_time_sec': cpu_time_sec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "b1938aee-dc52-4442-a1dc-34aee4f4db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Context manager (Credits: 'https://stackoverflow.com/questions/24983493/tracking-progress-of-joblib-parallel-execution')\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561b5a1c-c253-41b3-be40-866598943f7e",
   "metadata": {},
   "source": [
    "## (a) Rolling Horizon Global Weighted SAA (GwSAA)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f258a74-8ab3-4a35-9243-5abaaa22b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_global_not_reshaped'\n",
    "weightsmodel_name = 'rfwm_global_not_reshaped'\n",
    "\n",
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_global_not_reshaped_old_rf_params'\n",
    "weightsmodel_name = 'rfwm_global_not_reshaped_old_rf_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ea232ec-5727-401f-a60c-37e82bad7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "\n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/GwSAA_old_params',\n",
    "    'name_to_save': 'GwSAA_old_params',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5248f73a-8f0f-4b52-9d43-8f15a0aa0a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [00:52<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [07:57<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [29:13<00:00,  3.81s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [47:53<00:00,  6.25s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:25:29<00:00, 11.15s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set path\n",
    "if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Print:\n",
    "    print('Look-ahead tau='+str(tau)+'...')\n",
    "    \n",
    "    # Prepare data\n",
    "    samples = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')\n",
    "    weights = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')\n",
    "\n",
    "    samples, actuals, weights = prep_samples_and_weights(samples, weights, SKUs=SKUs, ts=ts)\n",
    "    \n",
    "    # For each product (SKU) k=1,...,M\n",
    "    with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "        resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(tau=tau, SKU=SKU, wsaamodel=WeightedSAA(), \n",
    "                                                                 samples=samples, weights=weights[SKU], actuals=actuals[SKU], \n",
    "                                                                 **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf022615-1746-4b73-915c-85bcf39f23c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3004c2-6cd9-468e-a4a1-2e210aeb4626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "ee71aa31-84dd-4431-ad7e-155f45fd671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RESHAPED WITH OLD HYPER PARAMS AND SCALING\n",
    "weightsmodel_name = 'rfwm_global_r_z_old_hyper_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "5ee948db-d539-4a84-9308-2d3c11bcf7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "\n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/GwSAA_r_z_old_params',\n",
    "    'name_to_save': 'GwSAA_r_z_old_params',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "44ce3344-76e8-4649-9638-b40ad679c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [03:00<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [14:42<00:00,  1.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [30:44<00:00,  4.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [39:51<00:00,  5.20s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [52:11<00:00,  6.81s/it]  \n"
     ]
    }
   ],
   "source": [
    "# Set path\n",
    "if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Print:\n",
    "    print('Look-ahead tau='+str(tau)+'...')\n",
    "    \n",
    "    # Prepare data\n",
    "\n",
    "    # Scaled samples and weights\n",
    "    samples = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')\n",
    "    weights = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')\n",
    "\n",
    "    samples_, actuals_, weights = prep_samples_and_weights(samples, weights, SKUs=SKUs, ts=ts)\n",
    "\n",
    "    # Unscaled samples, unscaled actuals\n",
    "    samples = {}\n",
    "    actuals = {}\n",
    "    for SKU in SKUs:\n",
    "        samples[SKU] = {}\n",
    "        actuals[SKU] = {}\n",
    "        for t in ts:\n",
    "            samples[SKU][t] = samples_[t] * y_scalers[t][SKU].scalers[0]\n",
    "            actuals[SKU][t] = actuals_[SKU][t] * y_scalers[t][SKU].scalers[0]\n",
    "    \n",
    "    # For each product (SKU) k=1,...,M\n",
    "    with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "        resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(tau=tau, SKU=SKU, wsaamodel=WeightedSAA(), \n",
    "                                                                 samples=samples[SKU], weights=weights[SKU], actuals=actuals[SKU], \n",
    "                                                                 **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459af199-2979-4aef-9acf-bbb77abe6c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ca461-bb05-4cd0-8196-344469fdb60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tau in taus:\n",
    "#     for t in ts:\n",
    "#         tau_=min(tau,T-t)\n",
    "        \n",
    "#         prep data ...\n",
    "        \n",
    "#         weightsmodel.fit(X, y)\n",
    "        \n",
    "#         for SKU in SKUs:\n",
    "            \n",
    "#             prep data ...\n",
    "            \n",
    "#             weightsmodel.predict(x)\n",
    "            \n",
    "#             q, status, solutions, gap = weightedsaa.apply()\n",
    "            \n",
    "#             I = I + q - d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab07e7d1-645f-41cb-8aa3-6156b37fdfef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31698510-db0c-4fbf-8c0f-2cedaf5e9d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16f0587-96a5-4076-a48e-a3efd316ce0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4236f61-52e6-4f37-8fe3-39c9d496c806",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0257f-eb49-43f3-9096-a6de3b1fcc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c313c1-cf05-4fbe-8e6d-741fd24e61f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd76b22-7b3a-426d-b3c6-897f0b0ea232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f990e6a-3366-45d5-8ccf-bdc88876c5fc",
   "metadata": {},
   "source": [
    "## (b) Rolling Horizon Global Robust Weighted SAA (GwSAA-R)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc8a233e-c6ef-4377-b8c6-a18de2a2666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_global_not_reshaped'\n",
    "weightsmodel_name = 'rfwm_global_not_reshaped'\n",
    "\n",
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_global_not_reshaped_old_rf_params'\n",
    "weightsmodel_name = 'rfwm_global_not_reshaped_old_rf_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20cc3496-a393-41bc-bedd-069d126aad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "\n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/GwSAAR',\n",
    "    'name_to_save_prefix': 'GwSAAR',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff7d42-139d-4b72-85bf-0fbed2a1448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [01:44<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [18:33<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  34%|      | 156/460 [17:25<33:22,  6.59s/it]  /home/fesc/.conda/envs/multiPeriodInv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Progress: 100%|| 460/460 [52:49<00:00,  6.89s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:25:25<00:00, 11.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [2:29:51<00:00, 19.55s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [01:44<00:00,  4.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [18:55<00:00,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [52:41<00:00,  6.87s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:24:59<00:00, 11.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [2:29:59<00:00, 19.56s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [01:45<00:00,  4.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:  36%|      | 167/460 [06:43<13:43,  2.81s/it]"
     ]
    }
   ],
   "source": [
    "# For each uncertainty set specification\n",
    "for e in [1,3,6,9,12]:\n",
    "    \n",
    "    # Print:\n",
    "    print('Uncertainty set parameter e='+str(e)+'...')\n",
    "    \n",
    "    # Update params\n",
    "    experiment_params['name_to_save'] = experiment_params['name_to_save_prefix']+'_e'+str(e).replace('.', '')\n",
    "    \n",
    "    # Set path\n",
    "    if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "    # For each look-ahead tau=0,...,4\n",
    "    for tau in taus:\n",
    "\n",
    "        # Print:\n",
    "        print('...look-ahead tau='+str(tau)+'...')\n",
    "\n",
    "        # Prepare data\n",
    "        samples = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')\n",
    "        weights = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')\n",
    "\n",
    "        samples, actuals, weights, epsilons = prep_samples_and_weights(samples, weights, e=e, SKUs=SKUs, ts=ts)\n",
    "\n",
    "        # For each product (SKU) k=1,...,M\n",
    "        with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "            resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(tau=tau, SKU=SKU, wsaamodel=RobustWeightedSAA(), \n",
    "                                                                     samples=samples, weights=weights[SKU], epsilons=epsilons[SKU],\n",
    "                                                                     actuals=actuals[SKU], e=e, **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7c739-3536-4f0c-be6b-a2b48663ac45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef5c6d-d226-46b8-a0eb-8bcbcf626885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a85bc-3db4-46fb-9020-ff7833462550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a87fe4-9f7b-45ec-9bd0-d89989d39f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "6eeadf33-8b97-40ad-8253-0ba1622b8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RESHAPED WITH OLD HYPER PARAMS AND SCALING\n",
    "weightsmodel_name = 'rfwm_global_r_z_old_hyper_params'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "99000e8f-70ab-4a1c-9083-b0e473031536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "\n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/GwSAAR_r_z_old_params',\n",
    "    'name_to_save_prefix': 'GwSAAR_r_z_old_params',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "ba4c0c25-ae35-447c-9661-44e36a645c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty set parameter e=1...\n",
      "...look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [06:35<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [23:09<00:00,  3.02s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [42:07<00:00,  5.49s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   8%|         | 38/460 [10:47<35:37,  5.07s/it]   /home/fesc/.conda/envs/multiPeriodInv/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:702: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "Progress: 100%|| 460/460 [59:11<00:00,  7.72s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:21:06<00:00, 10.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty set parameter e=3...\n",
      "...look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [06:30<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [22:40<00:00,  2.96s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [41:56<00:00,  5.47s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [58:51<00:00,  7.68s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:21:30<00:00, 10.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty set parameter e=6...\n",
      "...look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [06:35<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [22:20<00:00,  2.91s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [41:17<00:00,  5.39s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [58:42<00:00,  7.66s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:20:34<00:00, 10.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty set parameter e=9...\n",
      "...look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [06:38<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [22:14<00:00,  2.90s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [41:32<00:00,  5.42s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [59:03<00:00,  7.70s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:21:17<00:00, 10.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncertainty set parameter e=12...\n",
      "...look-ahead tau=0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [06:35<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [22:11<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [41:13<00:00,  5.38s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [58:15<00:00,  7.60s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...look-ahead tau=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|| 460/460 [1:21:18<00:00, 10.61s/it]  \n"
     ]
    }
   ],
   "source": [
    "# For each uncertainty set specification\n",
    "for e in [1,3,6,9,12]:\n",
    "    \n",
    "    # Print:\n",
    "    print('Uncertainty set parameter e='+str(e)+'...')\n",
    "    \n",
    "    # Update params\n",
    "    experiment_params['name_to_save'] = experiment_params['name_to_save_prefix']+'_e'+str(e).replace('.', '')\n",
    "    \n",
    "    # Set path\n",
    "    if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "    # For each look-ahead tau=0,...,4\n",
    "    for tau in taus:\n",
    "        \n",
    "        # Print:\n",
    "        print('...look-ahead tau='+str(tau)+'...')\n",
    "\n",
    "        # Prepare data\n",
    "        samples = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')\n",
    "        weights = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')\n",
    "\n",
    "        samples, actuals, weights, epsilons = prep_samples_and_weights(samples, weights, e=e, scalers=y_scalers, SKUs=SKUs, ts=ts)\n",
    "        \n",
    "        # For each product (SKU) k=1,...,M\n",
    "        with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "            resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(tau=tau, SKU=SKU, wsaamodel=RobustWeightedSAA(), \n",
    "                                                                     samples=samples[SKU], weights=weights[SKU], epsilons=epsilons[SKU],\n",
    "                                                                     actuals=actuals[SKU], e=e, **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154df6e7-8e2f-4e90-9f67-06ad2948df1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c876ec2-021d-4faf-a276-3f5dfb61a59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aad5e6-9d9f-4a82-8d69-f7bc278dc881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdc90b4-479e-4f37-8853-0b32f62cf52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562630df-2971-4cdd-8de2-c8220185aff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "177c4b64-a7ff-4b64-8e95-ddcd851acca5",
   "metadata": {},
   "source": [
    "## (c) Rolling Horizon Local Weighted SAA (wSAA)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c6aec-1d0e-4064-8b35-45ef1c641401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_local_not_reshaped'\n",
    "weightsmodel_name = 'rfwm_local_not_reshaped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86228ea-cc1f-447a-a3f1-ff95887b38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "    \n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/wSAA',\n",
    "    'name_to_save': 'wSAA',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e54514-7c62-4791-a34a-5f404b7dc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Print:\n",
    "    print('Look-ahead tau='+str(tau)+'...')\n",
    "    \n",
    "    # Prepare data\n",
    "    samples = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')\n",
    "    weights = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')\n",
    "\n",
    "    samples, actuals, weights = prep_samples_and_weights(samples, weights, SKUs=SKUs, ts=ts)\n",
    "    \n",
    "    # For each product (SKU) k=1,...,M\n",
    "    with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "        resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(tau=tau, SKU=SKU, wsaamodel=WeightedSAA(), \n",
    "                                                                 samples=samples[SKU], weights=weights[SKU], actuals=actuals[SKU], \n",
    "                                                                 **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d2e6d-cbc8-4156-9f6d-8db11f19889a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f3ae23-fecf-40c4-ab82-42d6f1d04b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35ca8e-b483-4cc4-97e1-30f3266dcfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a3ff83-6de0-4fad-8b99-a50eb9f3dd11",
   "metadata": {},
   "source": [
    "## (d) Rolling Horizon Local Robust Weighted SAA (wSAA-R)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7189defe-7b4b-433f-8bab-150e4c5250d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights model names\n",
    "weightsmodel_cv_name = 'cv_rfwm_local_not_reshaped'\n",
    "weightsmodel_name = 'rfwm_local_not_reshaped'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f83e339-7ec6-4a30-8315-3bdfd9616e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "    \n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/wSAAR',\n",
    "    'name_to_save_prefix': 'wSAAR',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b6457-abd5-4d2d-ac5d-4d74f6da08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each uncertainty set specification\n",
    "for e in [1,3,6,9,12]:\n",
    "    \n",
    "    # Print:\n",
    "    print('Uncertainty set parameter e='+str(e)+'...')\n",
    "        \n",
    "    # Update params\n",
    "    experiment_params['name_to_save'] = experiment_params['name_to_save_prefix']+'_e'+str(e).replace('.', '')\n",
    "    \n",
    "    # Set path\n",
    "    if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "    # For each look-ahead tau=0,...,4\n",
    "    for tau in taus:\n",
    "\n",
    "        # Print:\n",
    "        print('...look-ahead tau='+str(tau)+'...')\n",
    "\n",
    "        # Prepare data\n",
    "        samples = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_samples_tau'+str(tau)+'.joblib')\n",
    "        weights = joblib.load(PATH_WEIGHTSMODEL+'/'+weightsmodel_name+'_weights_tau'+str(tau)+'.joblib')\n",
    "\n",
    "        samples, actuals, weights, epsilons = prep_samples_and_weights(samples, weights, e=e, SKUs=SKUs, ts=ts)\n",
    "\n",
    "        # For each product (SKU) k=1,...,M\n",
    "        with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "            resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(tau=tau, SKU=SKU, wsaamodel=RobustWeightedSAA(), \n",
    "                                                                     samples=samples[SKU], weights=weights[SKU], epsilons=epsilons[SKU],\n",
    "                                                                     actuals=actuals[SKU], e=e, **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f42885-78fc-45fa-93d5-d6ea85789961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f602f846-a0d0-4b1f-b046-13dd0feaeaab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c356cc89-3dc4-45e1-ab7f-7bcf8c64274b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d980c8-d0f7-4f19-bd17-65100814f1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "650cf8f6-4fd6-4258-9498-759b49e4cbc0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## (e) Baseline model: Rolling Horizon Local Weighted SAA (SAA)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36241d0-6ac1-4fdf-9ead-18bc7d921e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "    \n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/SAA',\n",
    "    'name_to_save': 'SAA',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1c7f7-e1ae-4a9b-b474-19d1d5b10420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "# For each look-ahead tau=0,...,4\n",
    "for tau in taus:\n",
    "    \n",
    "    # Print:\n",
    "    print('Look-ahead tau='+str(tau)+'...')\n",
    "    \n",
    "    # Prepare data\n",
    "    samples = joblib.load(PATH_WEIGHTSMODEL+'/rfwm_local_samples_not_reshaped_tau'+str(tau)+'.joblib')\n",
    "    \n",
    "    samples, actuals = prep_samples_and_weights(samples, SKUs=SKUs, ts=ts)\n",
    "    \n",
    "    # For each product (SKU) k=1,...,M\n",
    "    with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "        resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(tau=tau, SKU=SKU, wsaamodel=WeightedSAA(), \n",
    "                                                                 samples=samples[SKU], actuals=actuals[SKU], \n",
    "                                                                 **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c1bc2c-df43-4c08-bd5a-08c91d99b970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554967d-2acd-45c3-8e68-10cd23695bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ccb147-9122-4e3f-8435-8c73275d2836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280f481-c0e0-4e07-86bc-c7e2b45fa4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64b4a736-d792-468a-86a1-8c95976293ed",
   "metadata": {},
   "source": [
    "## (f) Ex-post optimal model with deterministic demand\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696c509-5415-49f7-a94e-b69279244785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define experiment paramaters\n",
    "experiment_params = {\n",
    "            \n",
    "    # Cost param settings\n",
    "    'cost_params': cost_params,\n",
    "    \n",
    "    # Gurobi meta params\n",
    "    'LogToConsole': 0, \n",
    "    'Threads': 1, \n",
    "    'NonConvex': 2, \n",
    "    'PSDTol': 1e-3, # 0.1%\n",
    "    'MIPGap': 1e-3, # 0.1%\n",
    "    'NumericFocus': 0, \n",
    "    'obj_improvement': 1e-3, # 0.1%\n",
    "    'obj_timeout_sec': 3*60, # 3 min\n",
    "    'obj_timeout_max_sec': 10*60, # 10 min\n",
    "\n",
    "    # Program meta params\n",
    "    'path_to_save': PATH_RESULTS+'/ExPost',\n",
    "    'name_to_save': 'ExPost',\n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc93a75-85e3-428a-ac69-a824756d68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "samples = joblib.load(PATH_WEIGHTSMODEL+'/rfwm_local_samples_not_reshaped_tau'+str(0)+'.joblib')\n",
    "actuals = {}\n",
    "for SKU in SKUs:\n",
    "    d = []\n",
    "    for t in ts:\n",
    "        d = d + [samples[SKU][t]['y_test'].item()]\n",
    "    actuals[SKU] = np.array(d).reshape(1,len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67975180-c482-416c-9a03-18a97c42677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "if not os.path.exists(experiment_params['path_to_save']): os.mkdir(experiment_params['path_to_save'])\n",
    "\n",
    "# For each product (SKU) k=1,...,M\n",
    "with tqdm_joblib(tqdm(desc='Progress', total=len(SKUs))) as progress_bar:\n",
    "    resultslog = Parallel(n_jobs=32)(delayed(run_experiment)(SKU=SKU, wsaamodel=WeightedSAA(), actuals=actuals[SKU], **experiment_params) for SKU in SKUs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b089dda-c51e-4ad8-9246-acbf1729136c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d10eb6-98c8-49b9-8335-eac24a9e37c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ec46e-1bd4-4b0e-8a18-0c0caf340dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49b4a4-51a2-4f0f-93ce-9c0e10d84277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d08ce33-6328-49c9-a5ec-0a00cf7c0ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a9daf8-66fe-46ff-bbe5-daa14d847001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a8a38-1144-49c5-84e8-e4a11c6bebfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiPeriodInv",
   "language": "python",
   "name": "multiperiodinv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa32c966-eb6a-49ab-8484-fdd0b7e22e0a",
   "metadata": {},
   "source": [
    "**Import required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b518e25-3378-4cde-9fca-4ea5cccd902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "import pyreadr\n",
    "import json\n",
    "from pathlib import Path\n",
    "import joblib as joblib\n",
    "from joblib import dump, load, Parallel, delayed\n",
    "import os\n",
    "import itertools\n",
    "import contextlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Import D2D Multi-Period Inventory Control Library\n",
    "import WeightedSAA\n",
    "from WeightedSAA import RobustWeightedSAA\n",
    "from WeightedSAA import WeightedSAA\n",
    "from WeightedSAA import Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d1fa91-1e80-4537-aae6-29c813e271e2",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6350ee-9fc4-45ac-b616-082d6568aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model\n",
    "model = RobustWeightedSAA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce2e38-dbe6-4c26-b599-aa5649a1b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b31f0b-a036-480b-981d-42970e4dc0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca49fba-6106-4448-a755-b7c22849d0a4",
   "metadata": {},
   "source": [
    "**Experiments: Rolling Horizon Global Weighted SAA - Robust Extension**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a527ba6-8d32-46ef-a4c8-32d575a43f3f",
   "metadata": {},
   "source": [
    "First, we define a function that prepares the required input data for the optimization model across periods t=1...T. The data is prepared\n",
    "for a given SKU, rolling look-ahead horizon tau, test horizon T, sampling strategy, sale_yearweek splitting training and test data, and multiplier e for the robust extension's uncertainty set threshold epsilon.\n",
    "\n",
    "Where: epsilon[t] = e *  in-sample standard deviation of the current product (SKU).\n",
    "\n",
    "The function outputs the required data (y) and selectors identifying training (ids_train) and test (ids_test) data per t=1...T, as well as the weights for t=1...T and epsilons for t=1...T."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1271ed9-e1ed-4d3e-a154-bae757ccedf1",
   "metadata": {},
   "source": [
    "We now define a 'wrapper' function that iterates the experiment for a given SKU over differen cost parameter settins and lengths of the rolling look-ahead horizon tau.\n",
    "\n",
    "The function prepares and calls the experiment over t=1...T for each cost paramater setting and look-ahead horizon tau and then summarise the results including performance and performance meta inormation.\n",
    "\n",
    "It also saves the results in CSV format to the specified path and the function can also be used in parallel processing environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f9f901f-d243-4905-9447-c79ef4a7ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(SKU, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Description ...\n",
    "    \n",
    "    \n",
    "    Arguments:\n",
    "    \n",
    "        SKU: product (SKU) identifier\n",
    "        sale_yearweek: Last sale_yearweek of training data\n",
    "        T: Length T of the test horizon\n",
    "        tau: List of lengths of rolling look-ahead horizons\n",
    "        cost_params: dictionary/dictionary of dictionaries of cost parameters {'CR', 'K', 'u', 'h', 'b'}\n",
    "        gurobi_params: dictionary of gurobi meta params {'LogToConsole', 'Threads', 'NonConvex' \n",
    "                                                         'PSDTol', 'MIPGap': 'obj_improvement', \n",
    "                                                         'obj_timeout_sec'}\n",
    "        path: directory where results should be saved\n",
    "        model_name: model name for the file to save results\n",
    "        \n",
    "    Optional arguments:\n",
    "    \n",
    "        sampling: sampling strategy (either 'global' or 'local')\n",
    "        e: robust uncertainty set threshold multiplier\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "  \n",
    "    st_exec = time.time()\n",
    "    st_cpu = time.process_time()\n",
    "    \n",
    "    # Print progress\n",
    "    if kwargs['print_progress']: \n",
    "        print('SKU:', SKU)\n",
    "    \n",
    "    # Initialize results\n",
    "    evaluate = Evaluation()\n",
    "    results = pd.DataFrame()\n",
    "   \n",
    "    # For each cost param setting\n",
    "    for cost_params in kwargs['cost_params'].values():\n",
    "        \n",
    "        # Print progress\n",
    "        if kwargs['print_progress']: \n",
    "            print('... cost param setting:', cost_params)\n",
    "    \n",
    "        # For each rolling look-ahead horizon\n",
    "        for tau in kwargs['tau']:\n",
    "            \n",
    "            # Print progress\n",
    "            if kwargs['print_progress']: \n",
    "                print('...... look-ahead horizon:', tau)\n",
    "\n",
    "            ## Prepare data\n",
    "            #data = prep_data(SKU, tau, kwargs['T'], kwargs['sampling'], kwargs['sale_yearweek'], kwargs['e'])\n",
    "            #y, ids_train, ids_test, weights, epsilons = data\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "            ## Weighted (Robust) SAA\n",
    "            if 'sampling' in kwargs:\n",
    "    \n",
    "                ## Weighted Robust SAA  \n",
    "                if 'e' in kwargs:\n",
    "\n",
    "                    # Prepare data\n",
    "                    data = evaluate.prep_data(SKU, tau, kwargs['T'], kwargs['sale_yearweek'], PATH_DATA, PATH_SAMPLES, sampling=kwargs['sampling'], e=kwargs['e'])\n",
    "                    y, ids_train, ids_test, weights, epsilons = data\n",
    "                    \n",
    "                    # Create empty model\n",
    "                    wsaamodel = RobustWeightedSAA(**kwargs['gurobi_params'])\n",
    "\n",
    "                    # Run rolling horizon model over t=1...T\n",
    "                    result = evaluate.run_experiment(y, ids_train, ids_test, tau, wsaamodel, weights=weights, epsilons=epsilons, **cost_params)\n",
    "\n",
    "                ## Weighted SAA\n",
    "                else: \n",
    "                    \n",
    "                    # Prepare data\n",
    "                    data = evaluate.prep_data(SKU, tau, kwargs['T'], kwargs['sale_yearweek'], PATH_DATA, PATH_SAMPLES, sampling=kwargs['sampling'])\n",
    "                    y, ids_train, ids_test, weights, _ = data\n",
    "                    \n",
    "                    # Create empty model\n",
    "                    wsaamodel = WeightedSAA(**kwargs['gurobi_params'])\n",
    "\n",
    "                    # Run rolling horizon model over t=1...T\n",
    "                    result = evaluate.run_experiment(y, ids_train, ids_test, tau, wsaamodel, weights=weights, **cost_params)\n",
    "\n",
    "                    # result = evaluate.run_experiment(y=y, ids_train=ids_train, ids_test=ids_test, tau=tau, wsaamodel=wsaamodel,\n",
    "                    #                                  weights=weights, **cost_params)\n",
    "\n",
    "            ## SAA\n",
    "            else:\n",
    "                \n",
    "                # Prepare data\n",
    "                data = evaluate.prep_data(SKU, tau, kwargs['T'], kwargs['sale_yearweek'], PATH_DATA, PATH_SAMPLES)\n",
    "                y, ids_train, ids_test, _, _ = data\n",
    "\n",
    "                # Create empty model\n",
    "                wsaamodel = WeightedSAA(**kwargs['gurobi_params'])\n",
    "\n",
    "                # Run rolling horizon model over t=1...T\n",
    "                result = evaluate.run_experiment(y, ids_train, ids_test, tau, wsaamodel, **cost_params)\n",
    "\n",
    "            \n",
    "            ## ToDo: ExPost\n",
    "            \n",
    "            # Store result\n",
    "            meta = pd.DataFrame({\n",
    "\n",
    "                'SKU': np.repeat(SKU,kwargs['T']),\n",
    "                'n_periods': np.repeat(kwargs['T'],kwargs['T']),\n",
    "                'tau': np.repeat(tau,kwargs['T']),\n",
    "                'CR': np.repeat(cost_params['CR'],kwargs['T']),\n",
    "                'LogToConsole': np.repeat(kwargs['gurobi_params']['LogToConsole'],kwargs['T']),\n",
    "                'Threads': np.repeat(kwargs['gurobi_params']['Threads'],kwargs['T']),\n",
    "                'NonConvex': np.repeat(kwargs['gurobi_params']['NonConvex'],kwargs['T']),\n",
    "                'PSDTol': np.repeat(kwargs['gurobi_params']['PSDTol'],kwargs['T']),\n",
    "                'MIPGap': np.repeat(kwargs['gurobi_params']['MIPGap'],kwargs['T']),\n",
    "                'obj_improvement': np.repeat(kwargs['gurobi_params']['obj_improvement'],kwargs['T']),\n",
    "                'obj_timeout_sec': np.repeat(kwargs['gurobi_params']['obj_timeout_sec'],kwargs['T']),\n",
    "                'e': np.repeat(kwargs['e'],kwargs['T']) if 'e' in kwargs else np.repeat(0,kwargs['T']),\n",
    "                'epsilon': [epsilon for epsilon in epsilons] if 'e' in kwargs else np.repeat(0,kwargs['T'])\n",
    "            })\n",
    "\n",
    "            result = pd.concat([meta, result], axis=1)\n",
    "\n",
    "            # Store\n",
    "            if not results.empty:\n",
    "                results = results.append(result)   \n",
    "            else:\n",
    "                results = pd.DataFrame(result) \n",
    "\n",
    "    # Save result\n",
    "    save_log = results.to_csv(\n",
    "        path_or_buf=kwargs['path']+'/'+kwargs['model_name']+'_SKU'+str(SKU)+(('_e'+str(kwargs['e'])) if 'e' in kwargs else '')+'.csv', \n",
    "        sep=',', index=False\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Time\n",
    "    exec_time_sec = time.time() - st_exec\n",
    "    cpu_time_sec = time.process_time() - st_cpu\n",
    "    \n",
    "    # Print progress\n",
    "    if kwargs['print_progress']: \n",
    "        print('>>>> Done:',str(np.around(exec_time_sec/60,1)), 'minutes')\n",
    "\n",
    "    \n",
    "    # Returns results \n",
    "    if (kwargs['return_results'] if 'return_results' in kwargs else False):\n",
    "        return results\n",
    "    \n",
    "    # Returns a log\n",
    "    else:\n",
    "        return  {'SKU': SKU, 'exec_time_sec': exec_time_sec, 'cpu_time_sec': cpu_time_sec}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2532f938-6661-4734-98cd-5b7aa7d4bf57",
   "metadata": {},
   "source": [
    "This is a context manager for parellel execution with the purpose of reporting progress. \n",
    "\n",
    "Credits: https://stackoverflow.com/questions/24983493/tracking-progress-of-joblib-parallel-execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf2fc69-9614-41f2-ad27-0b6078b490c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d526b5-bbd5-4683-8afd-fd7000e98b9e",
   "metadata": {},
   "source": [
    "The code below runs the experiment for all given products (SKUs) and over parameter settings (e.g., cost parameters, horizon parameters, etc.). In total, we have 460 products (SKUs) with each 3 different cost parameter settings varying the critical ratio (CR) of holding and backlogging cost being {CR=0.50, CR=0.75, CR=0.90) and each 5 different lengths of the rolling look-ahead horizon tau being {1,2,3,4,5}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a356e375-ffc5-41e5-b865-5ba33e366da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder names as global variables\n",
    "os.chdir('/home/fesc/')\n",
    "global PATH_DATA, PATH_PARAMS, PATH_SAMPLES, PATH_RESULTS\n",
    "\n",
    "PATH_DATA = '/home/fesc/Data'\n",
    "PATH_PARAMS  = '/home/fesc/Data/Params'\n",
    "PATH_SAMPLES = '/home/fesc/Data/Samples'\n",
    "PATH_RESULTS = '/home/fesc/Data/Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb68ab7b-c496-4866-bc95-bf1393796064",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define paramaters\n",
    "params = {\n",
    "            \n",
    "    # Sampling strategy\n",
    "    'sampling': 'global',\n",
    "\n",
    "    # Robust uncertainty set threshold multiplier\n",
    "    'e': 12,\n",
    "\n",
    "    # Last sale_yearweek of training data\n",
    "    'sale_yearweek': 114,\n",
    "\n",
    "    # Length T of the test horizon\n",
    "    'T': 13,\n",
    "\n",
    "    # Lengths of rolling look-ahead horizons\n",
    "    'tau': [1,2,3,4,5],\n",
    "\n",
    "    # Cost param settings\n",
    "    'cost_params': {\n",
    "\n",
    "        1: {'CR': 0.50, 'K': 100, 'u': 0.5, 'h': 1, 'b': 1},\n",
    "        2: {'CR': 0.75, 'K': 100, 'u': 0.5, 'h': 1, 'b': 3},\n",
    "        3: {'CR': 0.90, 'K': 100, 'u': 0.5, 'h': 1, 'b': 9}\n",
    "\n",
    "    },\n",
    "\n",
    "    # Gurobi meta params\n",
    "    'gurobi_params': {\n",
    "\n",
    "        'LogToConsole': 1, \n",
    "        'Threads': 1, \n",
    "        'NonConvex': 2, \n",
    "        'PSDTol': 1e-3, # 0.1%\n",
    "        'MIPGap': 1e-3, # 0.1%\n",
    "        'obj_improvement': 1e-3, # 0.1%\n",
    "        'obj_timeout_sec': 3*60, # 3 min\n",
    "\n",
    "    },\n",
    "    \n",
    "    'path': PATH_RESULTS+'/GwSAAR',\n",
    "    'model_name': 'GwSAAR',\n",
    "    \n",
    "    'print_progress': False,\n",
    "    'return_results': False\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcb98a-9921-4119-894c-810addd74ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test for one product (SKU)\n",
    "test = run_experiments(SKU=2, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a5cc42-c9c8-40cf-b2a8-f6f357a1e4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9520b9d0-a042-46a0-a7e9-a9d981027b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8934596-1290-43ac-be67-602755752a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3174e9-5624-4d33-a3f8-0e8d9b9239bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/460 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Set path\n",
    "#os.mkdir(params['path'])\n",
    "       \n",
    "# Specify number of cores to use for parallel execution\n",
    "n_jobs = 32\n",
    "\n",
    "# Specify range of products (SKUs) to iterate over\n",
    "SKU_range = range(1,460+1)\n",
    "\n",
    "# Run for each product (SKU) in parallel\n",
    "with tqdm_joblib(tqdm(desc='Progress', total=len(SKU_range))) as progress_bar:\n",
    "    resultslog = Parallel(n_jobs=n_jobs)(delayed(run_experiments)(SKU, **params)\n",
    "                                         for SKU in SKU_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cca415-b544-4669-8041-69c43c1946d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultslog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660891c5-6ae7-497f-b8e3-d1c7ca4bf334",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d9ffa8-b71b-42d0-948f-261c2cf43e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d333fd7-2205-41f6-ba02-8b9ad3423dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multiPeriodInv",
   "language": "python",
   "name": "multiperiodinv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
